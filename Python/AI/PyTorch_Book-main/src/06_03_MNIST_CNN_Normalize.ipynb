{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + 標準化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定參數\n",
    "PATH_DATASETS = \"\" # 預設路徑\n",
    "BATCH_SIZE = 1024  # 批量\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟1：載入 MNIST 手寫阿拉伯數字資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "    ])\n",
    "\n",
    "# 下載 MNIST 手寫阿拉伯數字 訓練資料\n",
    "train_ds = MNIST(PATH_DATASETS, train=True, download=True, \n",
    "                 transform=transform)\n",
    "\n",
    "# 下載測試資料\n",
    "test_ds = MNIST(PATH_DATASETS, train=False, download=True, \n",
    "                 transform=transform)\n",
    "\n",
    "# 訓練/測試資料的維度\n",
    "print(train_ds.data.shape, test_ds.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟2：資料清理，此步驟無需進行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟3：進行特徵工程，將特徵縮放成(0, 1)之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.data = train_ds.data / 255.0\n",
    "# test_ds.data = test_ds.data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟4：資料分割，此步驟無需進行，載入MNIST資料時，已經切割好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟5：建立模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# W, F, P, S：image Width, Filter width, Padding, Stride \n",
    "# def Conv_Width(W, F, P, S):\n",
    "#     return math.floor(((W - F) + 2 * P) / S) + 1\n",
    "\n",
    "# # def Pool_Width(W, F, S):\n",
    "#     return math.floor((W - F) / S) + 1\n",
    "\n",
    "def Conv_Width(W, F, P, S):\n",
    "    return math.floor(((W - F + 2 * P) / S) + 1)\n",
    "\n",
    "def Conv_Output_Volume(W, F, P, S, out):\n",
    "    return Conv_Width(W, F, P, S) ** 2 * out\n",
    "\n",
    "# C: no of channels\n",
    "def Conv_Parameter_Count(F, C, out):\n",
    "    return F ** 2 * C * out\n",
    "\n",
    "def Pool_Width(W, F, P, S):\n",
    "    return Conv_Width(W, F, P, S)\n",
    "\n",
    "# filter_count: no of filter in last conv \n",
    "# stride count default value = Filter width\n",
    "def Pool_Output_Volume(W, F, P, S, filter_count):\n",
    "    return Conv_Output_Volume(W, F, P, S, filter_count)\n",
    "\n",
    "def Pool_Parameter_Count(W, F, S):\n",
    "    return 0\n",
    "\n",
    "def Conv_Pool_Width(W, F, P, S, F2, P2, S2, n):\n",
    "    for i in range(n):\n",
    "        W = Pool_Width(Conv_Width(W, F, P, S), F2, P2, S2)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 9216)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNet2\n",
    "l2_Width = Conv_Width(Conv_Width(28, 3, 0, 1), 3, 0, 1)\n",
    "p1_out = Pool_Output_Volume(l2_Width, 2, 0, 2, 64)\n",
    "l2_Width, p1_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟6：結合訓練資料及模型，進行模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d 參數： in-channel, out-channel, kernel size, Stride, Padding\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    loss_list = []    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx+1) % 10 == 0:\n",
    "            loss_list.append(loss.item())\n",
    "            batch = (batch_idx+1) * len(data)\n",
    "            data_count = len(train_loader.dataset)\n",
    "            percentage = (100. * (batch_idx+1) / len(train_loader))\n",
    "            print(f'Epoch {epoch}: [{batch:5d} / {data_count}] ({percentage:.0f} %)' +\n",
    "                  f'  Loss: {loss.item():.6f}')\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # 平均損失\n",
    "    test_loss /= len(test_loader.dataset) \n",
    "    # 顯示測試結果\n",
    "    data_count = len(test_loader.dataset)\n",
    "    percentage = 100. * correct / data_count \n",
    "    print(f'平均損失: {test_loss:.4f}, 準確率: {correct}/{data_count}' + \n",
    "          f' ({percentage:.2f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [ 6000 / 60000] (10 %)  Loss: 1.827908\n",
      "Epoch 1: [12000 / 60000] (20 %)  Loss: 1.248245\n",
      "Epoch 1: [18000 / 60000] (30 %)  Loss: 0.851046\n",
      "Epoch 1: [24000 / 60000] (40 %)  Loss: 0.567789\n",
      "Epoch 1: [30000 / 60000] (50 %)  Loss: 0.480891\n",
      "Epoch 1: [36000 / 60000] (60 %)  Loss: 0.498269\n",
      "Epoch 1: [42000 / 60000] (70 %)  Loss: 0.515344\n",
      "Epoch 1: [48000 / 60000] (80 %)  Loss: 0.483743\n",
      "Epoch 1: [54000 / 60000] (90 %)  Loss: 0.384602\n",
      "Epoch 1: [60000 / 60000] (100 %)  Loss: 0.386423\n",
      "Epoch 2: [ 6000 / 60000] (10 %)  Loss: 0.419692\n",
      "Epoch 2: [12000 / 60000] (20 %)  Loss: 0.417465\n",
      "Epoch 2: [18000 / 60000] (30 %)  Loss: 0.354337\n",
      "Epoch 2: [24000 / 60000] (40 %)  Loss: 0.400533\n",
      "Epoch 2: [30000 / 60000] (50 %)  Loss: 0.321174\n",
      "Epoch 2: [36000 / 60000] (60 %)  Loss: 0.270999\n",
      "Epoch 2: [42000 / 60000] (70 %)  Loss: 0.325577\n",
      "Epoch 2: [48000 / 60000] (80 %)  Loss: 0.223223\n",
      "Epoch 2: [54000 / 60000] (90 %)  Loss: 0.230614\n",
      "Epoch 2: [60000 / 60000] (100 %)  Loss: 0.210260\n",
      "Epoch 3: [ 6000 / 60000] (10 %)  Loss: 0.231238\n",
      "Epoch 3: [12000 / 60000] (20 %)  Loss: 0.234958\n",
      "Epoch 3: [18000 / 60000] (30 %)  Loss: 0.228746\n",
      "Epoch 3: [24000 / 60000] (40 %)  Loss: 0.217847\n",
      "Epoch 3: [30000 / 60000] (50 %)  Loss: 0.231476\n",
      "Epoch 3: [36000 / 60000] (60 %)  Loss: 0.220093\n",
      "Epoch 3: [42000 / 60000] (70 %)  Loss: 0.197167\n",
      "Epoch 3: [48000 / 60000] (80 %)  Loss: 0.192241\n",
      "Epoch 3: [54000 / 60000] (90 %)  Loss: 0.183291\n",
      "Epoch 3: [60000 / 60000] (100 %)  Loss: 0.168359\n",
      "Epoch 4: [ 6000 / 60000] (10 %)  Loss: 0.148564\n",
      "Epoch 4: [12000 / 60000] (20 %)  Loss: 0.185268\n",
      "Epoch 4: [18000 / 60000] (30 %)  Loss: 0.196135\n",
      "Epoch 4: [24000 / 60000] (40 %)  Loss: 0.136280\n",
      "Epoch 4: [30000 / 60000] (50 %)  Loss: 0.162360\n",
      "Epoch 4: [36000 / 60000] (60 %)  Loss: 0.187824\n",
      "Epoch 4: [42000 / 60000] (70 %)  Loss: 0.139198\n",
      "Epoch 4: [48000 / 60000] (80 %)  Loss: 0.163723\n",
      "Epoch 4: [54000 / 60000] (90 %)  Loss: 0.185190\n",
      "Epoch 4: [60000 / 60000] (100 %)  Loss: 0.123686\n",
      "Epoch 5: [ 6000 / 60000] (10 %)  Loss: 0.145032\n",
      "Epoch 5: [12000 / 60000] (20 %)  Loss: 0.152261\n",
      "Epoch 5: [18000 / 60000] (30 %)  Loss: 0.136532\n",
      "Epoch 5: [24000 / 60000] (40 %)  Loss: 0.132967\n",
      "Epoch 5: [30000 / 60000] (50 %)  Loss: 0.138478\n",
      "Epoch 5: [36000 / 60000] (60 %)  Loss: 0.122619\n",
      "Epoch 5: [42000 / 60000] (70 %)  Loss: 0.134862\n",
      "Epoch 5: [48000 / 60000] (80 %)  Loss: 0.122802\n",
      "Epoch 5: [54000 / 60000] (90 %)  Loss: 0.127834\n",
      "Epoch 5: [60000 / 60000] (100 %)  Loss: 0.105344\n",
      "Epoch 6: [ 6000 / 60000] (10 %)  Loss: 0.136601\n",
      "Epoch 6: [12000 / 60000] (20 %)  Loss: 0.091798\n",
      "Epoch 6: [18000 / 60000] (30 %)  Loss: 0.141214\n",
      "Epoch 6: [24000 / 60000] (40 %)  Loss: 0.101837\n",
      "Epoch 6: [30000 / 60000] (50 %)  Loss: 0.124889\n",
      "Epoch 6: [36000 / 60000] (60 %)  Loss: 0.082672\n",
      "Epoch 6: [42000 / 60000] (70 %)  Loss: 0.095368\n",
      "Epoch 6: [48000 / 60000] (80 %)  Loss: 0.134547\n",
      "Epoch 6: [54000 / 60000] (90 %)  Loss: 0.124970\n",
      "Epoch 6: [60000 / 60000] (100 %)  Loss: 0.099705\n",
      "Epoch 7: [ 6000 / 60000] (10 %)  Loss: 0.093872\n",
      "Epoch 7: [12000 / 60000] (20 %)  Loss: 0.062622\n",
      "Epoch 7: [18000 / 60000] (30 %)  Loss: 0.099677\n",
      "Epoch 7: [24000 / 60000] (40 %)  Loss: 0.086116\n",
      "Epoch 7: [30000 / 60000] (50 %)  Loss: 0.112758\n",
      "Epoch 7: [36000 / 60000] (60 %)  Loss: 0.086838\n",
      "Epoch 7: [42000 / 60000] (70 %)  Loss: 0.111109\n",
      "Epoch 7: [48000 / 60000] (80 %)  Loss: 0.104642\n",
      "Epoch 7: [54000 / 60000] (90 %)  Loss: 0.098056\n",
      "Epoch 7: [60000 / 60000] (100 %)  Loss: 0.068527\n",
      "Epoch 8: [ 6000 / 60000] (10 %)  Loss: 0.092580\n",
      "Epoch 8: [12000 / 60000] (20 %)  Loss: 0.115804\n",
      "Epoch 8: [18000 / 60000] (30 %)  Loss: 0.062573\n",
      "Epoch 8: [24000 / 60000] (40 %)  Loss: 0.110186\n",
      "Epoch 8: [30000 / 60000] (50 %)  Loss: 0.079838\n",
      "Epoch 8: [36000 / 60000] (60 %)  Loss: 0.104069\n",
      "Epoch 8: [42000 / 60000] (70 %)  Loss: 0.075697\n",
      "Epoch 8: [48000 / 60000] (80 %)  Loss: 0.104486\n",
      "Epoch 8: [54000 / 60000] (90 %)  Loss: 0.074292\n",
      "Epoch 8: [60000 / 60000] (100 %)  Loss: 0.091682\n",
      "Epoch 9: [ 6000 / 60000] (10 %)  Loss: 0.101767\n",
      "Epoch 9: [12000 / 60000] (20 %)  Loss: 0.120187\n",
      "Epoch 9: [18000 / 60000] (30 %)  Loss: 0.102182\n",
      "Epoch 9: [24000 / 60000] (40 %)  Loss: 0.063261\n",
      "Epoch 9: [30000 / 60000] (50 %)  Loss: 0.087738\n",
      "Epoch 9: [36000 / 60000] (60 %)  Loss: 0.054700\n",
      "Epoch 9: [42000 / 60000] (70 %)  Loss: 0.068586\n",
      "Epoch 9: [48000 / 60000] (80 %)  Loss: 0.068545\n",
      "Epoch 9: [54000 / 60000] (90 %)  Loss: 0.077363\n",
      "Epoch 9: [60000 / 60000] (100 %)  Loss: 0.052219\n",
      "Epoch 10: [ 6000 / 60000] (10 %)  Loss: 0.069837\n",
      "Epoch 10: [12000 / 60000] (20 %)  Loss: 0.062579\n",
      "Epoch 10: [18000 / 60000] (30 %)  Loss: 0.067839\n",
      "Epoch 10: [24000 / 60000] (40 %)  Loss: 0.055192\n",
      "Epoch 10: [30000 / 60000] (50 %)  Loss: 0.074554\n",
      "Epoch 10: [36000 / 60000] (60 %)  Loss: 0.087973\n",
      "Epoch 10: [42000 / 60000] (70 %)  Loss: 0.071844\n",
      "Epoch 10: [48000 / 60000] (80 %)  Loss: 0.070005\n",
      "Epoch 10: [54000 / 60000] (90 %)  Loss: 0.084270\n",
      "Epoch 10: [60000 / 60000] (100 %)  Loss: 0.051065\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.1\n",
    "\n",
    "# 改變批量以縮短訓練時間\n",
    "train_loader = DataLoader(train_ds, shuffle=True, batch_size=600)\n",
    "\n",
    "# 建立模型\n",
    "model = Net().to(device)\n",
    "\n",
    "# 設定優化器(optimizer)\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "loss_list = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss_list += train(model, device, train_loader, optimizer, epoch)\n",
    "    #test(model, device, test_loader)\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d1fc191d90>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 對訓練過程的損失繪圖\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_list, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟7：評分(Score Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均損失: 0.0439, 準確率: 9839/10000 (98.39%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 建立 DataLoader\n",
    "test_loader = DataLoader(test_ds, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 評分\n",
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual    : [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "prediction:  7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4\n"
     ]
    }
   ],
   "source": [
    "# 實際預測 20 筆資料\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        data, target = test_ds[i][0], test_ds[i][1]\n",
    "        data = data.reshape(1, *data.shape).to(device)\n",
    "        output = torch.argmax(model(data), axis=-1)\n",
    "        predictions.append(str(output.item()))\n",
    "\n",
    "# 比對\n",
    "print('actual    :', test_ds.targets[0:20].numpy())\n",
    "print('prediction: ', ' '.join(predictions[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "0~9預測機率: [[0.   0.   0.   0.   0.   0.91 0.09 0.   0.   0.  ]]\n",
      "0~9預測機率: [5]\n"
     ]
    }
   ],
   "source": [
    "# 顯示第 9 筆的機率\n",
    "import numpy as np\n",
    "\n",
    "i=8\n",
    "data = test_ds[i][0]\n",
    "data = data.reshape(1, *data.shape).to(device)\n",
    "print(data.shape)\n",
    "predictions = torch.softmax(model(data), dim=1)\n",
    "print(f'0~9預測機率: {np.around(predictions.cpu().detach().numpy(), 2)}')\n",
    "print(f'0~9預測機率: {np.argmax(predictions.cpu().detach().numpy(), axis=-1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第 9 筆圖像\n",
    "X2 = test_ds[i][0] \n",
    "plt.imshow(X2.reshape(28,28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.2078,  0.1740,  0.1740,  0.1740,\n",
       "          -0.2206,  1.2177,  0.6577,  0.1740, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.5304,  1.5232,  2.3378,  2.7960,  2.7960,  2.7960,\n",
       "           2.3124,  2.7069,  2.7960,  2.7960, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  1.3832,\n",
       "           2.6815,  2.7833,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.3777,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.2869,\n",
       "           1.7396,  1.7396,  1.7396,  1.7396, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.1696,  1.2559,  0.4922, -0.4242,  0.3013,  2.6051,\n",
       "           2.4651,  2.6051,  1.7141,  1.1541,  0.4540, -0.1696, -0.2842,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.2842,  2.1978,  2.7960,  0.5686, -0.4242, -0.4242, -0.0169,\n",
       "          -0.4242, -0.0424, -0.3988, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3478,\n",
       "           1.8287,  2.7960,  1.2559, -0.2969, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.2715,  1.2686,\n",
       "           2.7960,  2.5415, -0.2333, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.7468,  2.7960,\n",
       "           2.4142, -0.0678, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.4850,  2.7960,\n",
       "           1.7905, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.5542,  2.7960,\n",
       "           2.7069,  1.1923,  0.1995, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.8215,  2.7960,\n",
       "           2.7960,  2.7960,  2.7706,  1.4468,  0.7341,  1.1159,  0.6577,\n",
       "           0.1104,  0.1104,  0.6577, -0.0678, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.5287,  1.7141, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860,  0.2504,\n",
       "           2.3505,  2.4015,  2.7706,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.7833,  1.1541, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242,  0.4286,  0.4922,  2.1214,  2.7960,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.7960,  1.8032, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  1.1032,  2.7960,  2.7451,\n",
       "           1.5105,  0.2249,  1.6632,  2.7960,  2.7960,  1.8032, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  0.2122,  2.7960,  2.7960,\n",
       "           2.7960,  1.9687,  2.7833,  2.7960,  2.7960,  1.4596, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.3097,  1.7014,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7578,  1.8032, -0.2842, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1315,  1.8669,\n",
       "           2.5160,  2.7960,  2.3887,  1.2050, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.7595,  1.4723, -0.1442, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟8：評估，暫不進行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟9：模型佈署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型存檔\n",
    "torch.save(model, 'cnn_mnist_model.pth')\n",
    "\n",
    "# 模型載入\n",
    "model = torch.load('cnn_mnist_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟10：新資料預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4241 -0.4238 -0.4240 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4128 -0.2873 -0.1876 -0.2399 -0.3316 -0.3993 -0.4205 -0.4230 -0.4238 -0.4241 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4232 -0.1508 1.4752 1.6955 1.5618 1.3302 0.7282 0.1715 -0.0445 -0.1898 -0.2881 -0.3432 -0.4140 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4165 0.3541 1.7558 0.2630 0.1046 0.4295 1.1142 1.5121 1.6372 1.6048 1.6100 1.2776 -0.1703 -0.4233 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.3753 0.9540 0.9132 -0.3823 -0.4216 -0.4140 -0.3635 -0.2687 -0.1302 0.3836 1.9190 1.2196 -0.2537 -0.4237 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4205 -0.0364 1.6176 0.1261 -0.4192 -0.4242 -0.4242 -0.4242 -0.4228 -0.2158 1.3280 0.9206 -0.2690 -0.4204 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4241 -0.3353 1.0693 1.0346 -0.3362 -0.4241 -0.4242 -0.4242 -0.4242 -0.3797 0.7358 1.3350 -0.2278 -0.4225 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4223 -0.0058 1.5623 -0.0425 -0.4210 -0.4242 -0.4242 -0.4242 -0.4212 -0.0136 1.6577 0.2185 -0.4145 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4234 -0.2737 0.0662 -0.3856 -0.4242 -0.4242 -0.4242 -0.4242 -0.3651 0.9447 1.1022 -0.3386 -0.4241 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4230 -0.4204 -0.4240 -0.4242 -0.4242 -0.4242 -0.4223 -0.0569 1.6258 0.0795 -0.4194 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4102 0.5678 1.2262 -0.3336 -0.4241 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.3859 0.9854 0.7417 -0.4031 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.3667 1.1689 0.5179 -0.4135 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.3857 0.9725 0.8130 -0.3969 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4127 0.5248 1.2284 -0.3569 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4188 0.3064 1.3684 -0.3271 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4194 0.2741 1.3714 -0.3247 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4198 0.2502 1.4104 -0.3126 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4207 0.1622 1.5257 -0.2700 -0.4241 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4152 0.3461 1.2996 -0.3003 -0.4241 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4230 -0.3198 -0.2101 -0.4115 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4240 -0.4237 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n",
      "-0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 -0.4242 \n"
     ]
    }
   ],
   "source": [
    "# 使用小畫家，繪製 0~9，實際測試看看\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "\n",
    "no=7\n",
    "uploaded_file = f'./myDigits/{no}.png'\n",
    "image1 = io.imread(uploaded_file, as_gray=True)\n",
    "\n",
    "# 縮為 (28, 28) 大小的影像\n",
    "data_shape = data.shape\n",
    "image_resized = resize(image1, data_shape[2:], anti_aliasing=True)    \n",
    "X1 = image_resized.reshape(*data_shape) \n",
    "\n",
    "# 反轉顏色，顏色0為白色，與 RGB 色碼不同，它的 0 為黑色\n",
    "X1 = 1.0-X1\n",
    "\n",
    "# 圖像轉換\n",
    "X1 = (X1 - 0.1307) / 0.3081  \n",
    "\n",
    "for i in range(X1[0][0].shape[0]):\n",
    "    for j in range(X1[0][0].shape[1]):\n",
    "        print(f'{X1[0][0][i][j]:.4f}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第1張圖片圖像\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 繪製點陣圖，cmap='gray':灰階\n",
    "plt.imshow(X1.reshape(28,28), cmap='gray')\n",
    "\n",
    "# 隱藏刻度\n",
    "plt.axis('off') \n",
    "\n",
    "# 顯示圖形\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (28,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000111100000000000000',\n",
       " '0000000000100011111100000000',\n",
       " '0000000001100000001100000000',\n",
       " '0000000001000000011000000000',\n",
       " '0000000011000000010000000000',\n",
       " '0000000010000000100000000000',\n",
       " '0000000000000001100000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000010000000000000',\n",
       " '0000000000000010000000000000',\n",
       " '0000000000000011000000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000001000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將非0的數字轉為1，顯示第1張圖片\n",
    "X2 = X1[0][0].copy()\n",
    "X2[X2>(0.1 + 0.1307) / 0.3081]=1 # 0.1 將淺色忽略\n",
    "print(type(X2), X2[0].shape)\n",
    "# 將轉換後二維內容顯示出來，隱約可以看出數字為 5\n",
    "text_image=[]\n",
    "for i in range(X2.shape[0]):\n",
    "    text_image.append(''.join(X2[i].astype(int).astype(str)))\n",
    "text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shape = X1.shape\n",
    "data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual/prediction: 7 7\n"
     ]
    }
   ],
   "source": [
    "X1 = torch.FloatTensor(X1).to(device)\n",
    "\n",
    "# 預測\n",
    "predictions = model(X1)\n",
    "print(f'actual/prediction: {no} {np.argmax(predictions.detach().cpu().numpy())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9622, -1.9524, -3.2974, -2.3534, -5.0511, -4.1827, -6.3905, -0.6559,\n",
       "         -4.3466, -1.7828]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual/prediction: 0 0\n",
      "actual/prediction: 1 1\n",
      "actual/prediction: 2 2\n",
      "actual/prediction: 3 3\n",
      "actual/prediction: 4 4\n",
      "actual/prediction: 5 5\n",
      "actual/prediction: 6 6\n",
      "actual/prediction: 7 7\n",
      "actual/prediction: 8 8\n",
      "actual/prediction: 9 8\n"
     ]
    }
   ],
   "source": [
    "# 讀取影像並轉為單色\n",
    "for i in range(10):\n",
    "    uploaded_file = f'./myDigits/{i}.png'\n",
    "    image1 = io.imread(uploaded_file, as_gray=True)\n",
    "\n",
    "    # 縮為 (28, 28) 大小的影像\n",
    "    image_resized = resize(image1, data_shape[2:], anti_aliasing=True)    \n",
    "    X1 = image_resized.reshape(*data_shape) \n",
    "\n",
    "    # 反轉顏色，顏色0為白色，與 RGB 色碼不同，它的 0 為黑色\n",
    "    X1 = 1.0-X1\n",
    "    \n",
    "    # 圖像轉換\n",
    "    X1 = (X1 - 0.1307) / 0.3081  \n",
    "    \n",
    "    X1 = torch.FloatTensor(X1).to(device)\n",
    "    \n",
    "    # 預測\n",
    "    predictions = torch.softmax(model(X1), dim=1)\n",
    "    # print(np.around(predictions.cpu().detach().numpy(), 2))\n",
    "    print(f'actual/prediction: {i} {np.argmax(predictions.detach().cpu().numpy())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
