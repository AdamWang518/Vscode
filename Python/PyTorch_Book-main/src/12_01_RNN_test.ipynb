{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 簡單的RNN實作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程式參考來源：\n",
    "- https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\n",
    "- https://pytorch.org/text/stable/vocab.html\n",
    "- https://pytorch.org/text/stable/functional.html#to-tensor\n",
    "- https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入相關套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入層測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2854,  0.4994, -1.2292,  0.0285, -1.4484],\n",
      "         [-0.4937,  0.7987, -0.5471,  1.5526,  1.3826],\n",
      "         [-0.1778, -1.9945,  0.3916,  0.7550,  0.2322]],\n",
      "\n",
      "        [[ 0.2465,  0.7877,  0.3312,  0.5031, -0.3601],\n",
      "         [ 0.9708,  0.3138, -0.4496,  1.8550,  0.6466],\n",
      "         [ 2.1568,  0.5826, -1.4558,  0.1674,  1.6133]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor([[0,1,2], [3,4,5]])\n",
    "embeds = nn.Embedding(6, 5) \n",
    "print(embeds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2854,  0.4994, -1.2292,  0.0285, -1.4484],\n",
       "        [-0.4937,  0.7987, -0.5471,  1.5526,  1.3826],\n",
       "        [-0.1778, -1.9945,  0.3916,  0.7550,  0.2322],\n",
       "        [ 0.2465,  0.7877,  0.3312,  0.5031, -0.3601],\n",
       "        [ 0.9708,  0.3138, -0.4496,  1.8550,  0.6466],\n",
       "        [ 2.1568,  0.5826, -1.4558,  0.1674,  1.6133]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2021, -1.0623,  0.0677,  0.8205,  0.7972],\n",
      "         [ 1.8586, -0.6237,  0.9995, -0.7118,  0.2388],\n",
      "         [-1.8304, -0.7225, -0.9457, -0.3937,  0.3253]],\n",
      "\n",
      "        [[ 0.9283,  1.0477,  0.8933, -0.2366, -0.7531],\n",
      "         [-1.5280,  0.4154,  0.2127,  1.0361,  0.9087],\n",
      "         [-1.5227,  0.3780,  0.1096,  1.3931, -1.5150]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor([[1,2,3], [4,5,6]])\n",
    "embeds = nn.Embedding(7, 5) \n",
    "print(embeds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.6216, -2.1906, -0.0539,  0.1866,  0.1487],\n",
      "         [-1.3029,  0.7337, -0.1752,  0.2191,  0.7611],\n",
      "         [-1.0816,  0.1376,  2.1151,  1.3313,  0.3332]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[ 1.6070,  0.5820,  0.4085, -1.8771,  0.0628],\n",
      "         [-0.5556, -1.2174, -0.7017, -0.1620,  0.8118]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.6216, -2.1906, -0.0539,  0.1866,  0.1487],\n",
       "        [-1.3029,  0.7337, -0.1752,  0.2191,  0.7611],\n",
       "        [-1.0816,  0.1376,  2.1151,  1.3313,  0.3332],\n",
       "        [ 1.6070,  0.5820,  0.4085, -1.8771,  0.0628],\n",
       "        [-0.5556, -1.2174, -0.7017, -0.1620,  0.8118],\n",
       "        [ 0.0888,  0.6752,  1.1217, -0.4797, -0.1823]], requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = nn.Embedding(6, 5) \n",
    "x1 = torch.LongTensor([[0,1,2]])\n",
    "x2 = torch.LongTensor([[3,4]])\n",
    "print(embeds(x1))\n",
    "print(embeds(x2))\n",
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1070, -0.0912, -1.6728, -0.8792,  0.5309],\n",
      "         [-0.9439,  1.1110,  0.0358, -0.9717,  2.7881],\n",
      "         [-0.3279, -0.7180, -1.7330, -1.2374,  1.7251]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[-0.0248,  0.6468, -0.8845, -1.1123, -0.3905],\n",
      "         [-0.1012,  0.2742, -0.2391,  1.9627,  1.2456]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[-0.0248,  0.6468, -0.8845, -1.1123, -0.3905],\n",
      "         [-0.1012,  0.2742, -0.2391,  1.9627,  1.2456]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1070, -0.0912, -1.6728, -0.8792,  0.5309],\n",
       "        [-0.9439,  1.1110,  0.0358, -0.9717,  2.7881],\n",
       "        [-0.3279, -0.7180, -1.7330, -1.2374,  1.7251],\n",
       "        [-0.0248,  0.6468, -0.8845, -1.1123, -0.3905],\n",
       "        [-0.1012,  0.2742, -0.2391,  1.9627,  1.2456],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = nn.Embedding(6, 5, 5) \n",
    "x1 = torch.LongTensor([[0,1,2]])\n",
    "x2 = torch.LongTensor([[3,4]])\n",
    "x3 = torch.LongTensor([[3,4]])\n",
    "print(embeds(x1))\n",
    "print(embeds(x2))\n",
    "print(embeds(x3))\n",
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4981,  1.1051,  1.0376,  0.2448,  0.6538]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 測試資料\n",
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "# 詞彙表(vocabulary)含2個單字, 轉換為5維的向量\n",
    "embeds = nn.Embedding(2, 5) \n",
    "# 測試 hello\n",
    "lookup_tensor = torch.LongTensor([word_to_ix[\"hello\"]])\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN層測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 10])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5, 3, 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 20]) torch.Size([2, 20])\n"
     ]
    }
   ],
   "source": [
    "# 測試資料\n",
    "input = torch.randn(5, 10)\n",
    "# 建立 RNN 物件\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "# RNN 處理\n",
    "output, hn = rnn(input)\n",
    "# 顯示輸出及隱藏層的維度\n",
    "print(output.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 20]) torch.Size([2, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "# 測試資料\n",
    "input = torch.randn(5, 4, 10)\n",
    "# 建立 RNN 物件\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "# RNN 處理\n",
    "output, hn = rnn(input)\n",
    "# 顯示輸出及隱藏層的維度\n",
    "print(output.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20]) torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 測試資料\n",
    "input = torch.randn(5, 3, 10)\n",
    "# 建立 RNN 物件\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "# 隱藏層的輸入\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "# RNN 處理\n",
    "output, hn = rnn(input, h0)\n",
    "# 顯示輸出及隱藏層的維度\n",
    "print(output.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['could', 'have', 'done', 'better', '.']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "text = 'Could have done better.'        \n",
    "tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詞彙表處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "# BOW 統計\n",
    "counter = Counter(tokenizer(text))\n",
    "# 依出現次數降冪排列\n",
    "sorted_by_freq_tuples = sorted(counter.items(), \n",
    "                       key=lambda x: x[1], reverse=True)\n",
    "# 建立詞彙字典\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "# 建立詞彙表物件，並加一個未知單字(unknown)的索引值\n",
    "vocab_object = torchtext.vocab.vocab(ordered_dict, specials=[\"<unk>\"])\n",
    "# 設定詞彙表預設值為未知單字(unknown)的索引值\n",
    "vocab_object.set_default_index(vocab_object[\"<unk>\"])\n",
    "\n",
    "# 測試\n",
    "vocab_object['done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'could', 'have', 'done', 'better', '.']"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_object.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_object.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def create_vocabulary(text_list):\n",
    "    # 取得標點符號\n",
    "    stopwords = list(string.punctuation)\n",
    "    \n",
    "    # 去除標點符號\n",
    "    clean_text_list = []\n",
    "    clean_tokens_list = []\n",
    "    for text in text_list:\n",
    "        tokens = tokenizer(text) \n",
    "        clean_tokens = []\n",
    "        for w in tokens:\n",
    "            if w not in stopwords:\n",
    "                clean_tokens.append(w)\n",
    "        clean_tokens_list += clean_tokens\n",
    "        clean_text_list.append(' '.join(clean_tokens)) \n",
    "        \n",
    "    # 建立詞彙表物件\n",
    "    counter = Counter(clean_tokens_list)    \n",
    "    sorted_by_freq_tuples = sorted(counter.items(), \n",
    "                                   key=lambda x: x[1], reverse=True)\n",
    "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "    vocab_object = torchtext.vocab.vocab(ordered_dict, specials=[\"<unk>\"])\n",
    "    vocab_object.set_default_index(vocab_object[\"<unk>\"])\n",
    "    \n",
    "    # 將輸入字串轉為索引值：自詞彙表物件查詢索引值\n",
    "    clean_index_list = []\n",
    "    for clean_tokens_list in clean_text_list:\n",
    "        clean_index_list.append(\n",
    "            vocab_object.lookup_indices(clean_tokens_list.split(' ')))\n",
    "    \n",
    "    # 輸出 詞彙表物件、去除標點符號的字串陣列、字串陣列的索引值\n",
    "    return vocab_object, clean_text_list, clean_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'work',\n",
       " 'done',\n",
       " 'good',\n",
       " 'effort',\n",
       " 'poor',\n",
       " 'well',\n",
       " 'great',\n",
       " 'nice',\n",
       " 'excellent',\n",
       " 'weak',\n",
       " 'not',\n",
       " 'could',\n",
       " 'have',\n",
       " 'better']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "\n",
    "vocab_object, clean_text_list, clean_index_list = create_vocabulary(docs)\n",
    "vocab_object.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well done',\n",
       " 'good work',\n",
       " 'great effort',\n",
       " 'nice work',\n",
       " 'excellent',\n",
       " 'weak',\n",
       " 'poor effort',\n",
       " 'not good',\n",
       " 'poor work',\n",
       " 'could have done better']"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 2],\n",
       " [3, 1],\n",
       " [7, 4],\n",
       " [8, 1],\n",
       " [9],\n",
       " [10],\n",
       " [5, 4],\n",
       " [11, 3],\n",
       " [5, 1],\n",
       " [12, 13, 2, 14]]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整合以上功能，實作一個簡單的案例，說明相關的處理程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立詞彙表：整理輸入語句，截長補短，使語句長度一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  2,  0,  0],\n",
       "        [ 3,  1,  0,  0],\n",
       "        [ 7,  4,  0,  0],\n",
       "        [ 8,  1,  0,  0],\n",
       "        [ 9,  0,  0,  0],\n",
       "        [10,  0,  0,  0],\n",
       "        [ 5,  4,  0,  0],\n",
       "        [11,  3,  0,  0],\n",
       "        [ 5,  1,  0,  0],\n",
       "        [12, 13,  2, 14]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 4      # 語句最大字數\n",
    "# 測試資料\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better']\n",
    "\n",
    "vocab_object, clean_text_list, clean_index_list = create_vocabulary(docs)\n",
    "\n",
    "# 若字串過長，刪除多餘單字\n",
    "clean_index_list = torchtext.functional.truncate(clean_index_list, maxlen)\n",
    "\n",
    "# 若字串長度不足，後面補 0\n",
    "while len(clean_index_list[0]) < maxlen:\n",
    "    clean_index_list[0] += [0]\n",
    "torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足補0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 測試 \n",
    "embeds = nn.Embedding(vocab_object.__len__(), 5) \n",
    "X = torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足補0\n",
    "embed_output = embeds(X)\n",
    "print(embed_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加上完全連接層(Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim * maxlen, num_class) # 要乘以 maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        out = embedded.reshape(embedded.size(0), -1) # 轉換成1維\n",
    "        return self.fc(out)\n",
    "\n",
    "model = RecurrentNet(vocab_object.__len__(), 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 另一種寫法，使用EmbeddingBag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "model = RecurrentNet(vocab_object.__len__(), 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.72728\n",
      "Epoch: 100, loss: 0.06390\n",
      "Epoch: 200, loss: 0.00598\n",
      "Epoch: 300, loss: 0.00140\n",
      "Epoch: 400, loss: 0.00052\n",
      "Epoch: 500, loss: 0.00016\n",
      "Epoch: 600, loss: 0.00004\n",
      "Epoch: 700, loss: 0.00001\n",
      "Epoch: 800, loss: 0.00000\n",
      "Epoch: 900, loss: 0.00000\n"
     ]
    }
   ],
   "source": [
    "# 定義 10 個語句的正面(1)或負面(0)的情緒\n",
    "y = torch.FloatTensor([1,1,1,1,1,0,0,0,0,0])\n",
    "X = torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足補0\n",
    "\n",
    "# 指定優化器、損失函數\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 模型訓練\n",
    "for epoch in range(1000):\n",
    "    outputs = model.forward(X) #forward pass\n",
    "    optimizer.zero_grad() \n",
    "    loss = criterion(outputs.reshape(-1), y)\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    if epoch % 100 == 0:\n",
    "        #print(outputs.shape)\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():1.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00],\n",
       "        [ 9.9983e-01],\n",
       "        [ 1.0002e+00],\n",
       "        [ 9.9990e-01],\n",
       "        [ 1.0000e+00],\n",
       "        [-3.0272e-05],\n",
       "        [-3.2104e-04],\n",
       "        [ 1.9193e-05],\n",
       "        [ 3.5113e-04],\n",
       "        [-7.1526e-07]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型評估\n",
    "model.eval()\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0002e+00],\n",
       "        [ 1.0000e+00],\n",
       "        [-3.2104e-04]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試資料\n",
    "test_docs = ['great effort', 'well done',\n",
    "        'poor effort']\n",
    "\n",
    "# 轉成數值 \n",
    "clean_index_list = []\n",
    "for text in test_docs:\n",
    "    clean_index_list.append(vocab_object.lookup_indices(text.split(' ')))\n",
    "while len(clean_index_list[0]) < maxlen:\n",
    "    clean_index_list[0] += [0]\n",
    "\n",
    "clean_index_list = torchtext.functional.truncate(clean_index_list, maxlen)    \n",
    "X = torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足補0\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用詞向量(Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取 GloVe 50維的詞向量，轉換為GloVe 50維的詞向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0266,  1.3357, -1.0280, -0.3729,  0.5201, -0.1270, -0.3543,  0.3782,\n",
       "         -0.2972,  0.0939, -0.0341,  0.9296, -0.1402, -0.6330,  0.0208, -0.2153,\n",
       "          0.9692,  0.4765, -1.0039, -0.2401, -0.3632, -0.0048, -0.5148, -0.4626,\n",
       "          1.2447, -1.8316, -1.5581, -0.3747,  0.5336,  0.2088,  3.2209,  0.6455,\n",
       "          0.3744, -0.1766, -0.0242,  0.3379, -0.4190,  0.4008, -0.1145,  0.0512,\n",
       "         -0.1521,  0.2986, -0.4405,  0.1109, -0.2463,  0.6625, -0.2695, -0.4966,\n",
       "         -0.4162, -0.2549]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/text/stable/vocab.html#glove\n",
    "examples = ['great']\n",
    "vec = torchtext.vocab.GloVe(name='6B', dim=50)\n",
    "ret = vec.get_vecs_by_tokens(examples, lower_case_backup=True)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400000, 50])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.stoi['great']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding 不需訓練，直接設定嵌入層權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self, weights_matrix, num_embeddings, embedding_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(num_embeddings, embedding_dim)\n",
    "        # 設定嵌入層權重\n",
    "        self.embedding.load_state_dict({'weight': weights_matrix})\n",
    "        self.fc = nn.Linear(embedding_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試資料轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better']\n",
    "\n",
    "# 將詞彙表轉為詞向量\n",
    "clean_text_list = []\n",
    "clean_tokens_list = []\n",
    "for i, text in enumerate(docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            clean_tokens.append(w)\n",
    "    clean_tokens_list += clean_tokens   \n",
    "    clean_text_list.append(clean_tokens)  \n",
    "    tokens_vec = vec.get_vecs_by_tokens(clean_tokens)\n",
    "vocab_list = list(set(clean_tokens_list))            \n",
    "weights_matrix = vec.get_vecs_by_tokens(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  6,  0,  0],\n",
       "        [10,  4,  0,  0],\n",
       "        [13, 12,  0,  0],\n",
       "        [ 0,  4,  0,  0],\n",
       "        [ 7,  0,  0,  0],\n",
       "        [ 8,  0,  0,  0],\n",
       "        [ 2, 12,  0,  0],\n",
       "        [ 5, 10,  0,  0],\n",
       "        [ 2,  4,  0,  0],\n",
       "        [ 3, 11,  6,  1]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義 10 個語句的正面(1)或負面(0)的情緒\n",
    "y = torch.FloatTensor([1,1,1,1,1,0,0,0,0,0])\n",
    "X = torch.LongTensor(np.zeros((len(docs), maxlen)))\n",
    "for i, item in enumerate(clean_text_list):\n",
    "    for j, token in enumerate(item):\n",
    "        if token in vocab_list:\n",
    "            X[i, j] = vocab_list.index(token)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nice',\n",
       " 'better',\n",
       " 'poor',\n",
       " 'could',\n",
       " 'work',\n",
       " 'not',\n",
       " 'done',\n",
       " 'excellent',\n",
       " 'weak',\n",
       " 'well',\n",
       " 'good',\n",
       " 'have',\n",
       " 'effort',\n",
       " 'great']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.03547\n",
      "Epoch: 100, loss: 0.09790\n",
      "Epoch: 200, loss: 0.02937\n",
      "Epoch: 300, loss: 0.00643\n",
      "Epoch: 400, loss: 0.00280\n",
      "Epoch: 500, loss: 0.00141\n",
      "Epoch: 600, loss: 0.00067\n",
      "Epoch: 700, loss: 0.00031\n",
      "Epoch: 800, loss: 0.00013\n",
      "Epoch: 900, loss: 0.00006\n"
     ]
    }
   ],
   "source": [
    "# 建立模型物件\n",
    "model = RecurrentNet(torch.FloatTensor(weights_matrix), len(vocab_list), 50, 1)\n",
    "\n",
    "# 指定優化器、損失函數\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 模型訓練\n",
    "for epoch in range(1000):\n",
    "    outputs = model.forward(X) #forward pass\n",
    "    optimizer.zero_grad() \n",
    "    loss = criterion(outputs.reshape(-1), y)\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    if epoch % 100 == 0:\n",
    "        #print(outputs.shape)\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():1.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0005e+00],\n",
       "        [ 1.0003e+00],\n",
       "        [ 1.0043e+00],\n",
       "        [ 9.9065e-01],\n",
       "        [ 1.0017e+00],\n",
       "        [ 1.3793e-03],\n",
       "        [-6.5045e-03],\n",
       "        [-4.8908e-05],\n",
       "        [ 9.2722e-03],\n",
       "        [-1.0637e-04]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型評估\n",
    "model.eval()\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0043],\n",
       "        [ 1.0005],\n",
       "        [-0.0065]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試資料\n",
    "test_docs = ['great effort', 'well done',\n",
    "        'poor effort']\n",
    "\n",
    "# 轉成數值 \n",
    "X = torch.LongTensor(np.zeros((len(test_docs), maxlen)))\n",
    "clean_text_list = []\n",
    "for i, text in enumerate(test_docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            clean_tokens.append(w)\n",
    "    clean_text_list.append(clean_tokens)  \n",
    "\n",
    "for i, item in enumerate(clean_text_list):\n",
    "    for j, token in enumerate(item):\n",
    "        if token in vocab_list:\n",
    "            X[i, j] = vocab_list.index(token)\n",
    "\n",
    "# 預測            \n",
    "model.eval()        \n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將整個詞向量設定為嵌入層權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNet2(nn.Module):\n",
    "    def __init__(self, vec, embedding_dim, num_class):\n",
    "        super().__init__()\n",
    "        # 將整個詞向量設定為嵌入層權重，且嵌入層設為不訓練\n",
    "        self.embedding = nn.EmbeddingBag.from_pretrained(vec, freeze=True)\n",
    "        self.fc = nn.Linear(embedding_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)\n",
    "    \n",
    "model = RecurrentNet2(vec.vectors, vec.dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 143,  751,    0,    0],\n",
       "        [ 219,  161,    0,    0],\n",
       "        [ 353,  968,    0,    0],\n",
       "        [3082,  161,    0,    0],\n",
       "        [4345,    0,    0,    0],\n",
       "        [2690,    0,    0,    0],\n",
       "        [ 992,  968,    0,    0],\n",
       "        [  36,  219,    0,    0],\n",
       "        [ 992,  161,    0,    0],\n",
       "        [  94,   33,  751,  439]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試資料\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better']\n",
    "\n",
    "# 轉成數值 \n",
    "X = torch.LongTensor(np.zeros((len(docs), maxlen)))\n",
    "\n",
    "for i, text in enumerate(docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    j=0\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            # 轉成詞向量索引值 \n",
    "            X[i, j] = vec.stoi[w]\n",
    "            j+=1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.26617\n",
      "Epoch: 100, loss: 0.12657\n",
      "Epoch: 200, loss: 0.07799\n",
      "Epoch: 300, loss: 0.05655\n",
      "Epoch: 400, loss: 0.04253\n",
      "Epoch: 500, loss: 0.03269\n",
      "Epoch: 600, loss: 0.02547\n",
      "Epoch: 700, loss: 0.01998\n",
      "Epoch: 800, loss: 0.01569\n",
      "Epoch: 900, loss: 0.01227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8730],\n",
       "        [ 0.9340],\n",
       "        [ 1.0150],\n",
       "        [ 0.9696],\n",
       "        [ 0.9747],\n",
       "        [-0.0099],\n",
       "        [-0.0561],\n",
       "        [ 0.2156],\n",
       "        [ 0.1366],\n",
       "        [-0.0677]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定優化器、損失函數\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 模型訓練\n",
    "for epoch in range(1000):\n",
    "    outputs = model.forward(X) #forward pass\n",
    "    optimizer.zero_grad() \n",
    "    loss = criterion(outputs.reshape(-1), y)\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    if epoch % 100 == 0:\n",
    "        #print(outputs.shape)\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():1.5f}\")\n",
    "\n",
    "model.eval()        \n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[353, 664,   0,   0],\n",
       "        [143, 751,   0,   0],\n",
       "        [992, 664,   0,   0]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試資料\n",
    "test_docs = ['great job', 'well done',\n",
    "        'poor job']\n",
    "\n",
    "# 轉成數值 \n",
    "X = torch.LongTensor(np.zeros((len(test_docs), maxlen)))\n",
    "for i, text in enumerate(test_docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    j=0\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            X[i, j] = vec.stoi[w]\n",
    "            j+=1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6623],\n",
       "        [ 0.8730],\n",
       "        [-0.4088]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 預測            \n",
    "model.eval()        \n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
