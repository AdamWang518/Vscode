{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手寫阿拉伯數字辨識 完整版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DATASETS = \"\" # 預設路徑\n",
    "BATCH_SIZE = 1024  # 批量\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟1：載入 MNIST 手寫阿拉伯數字資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 下載 MNIST 手寫阿拉伯數字 訓練資料\n",
    "train_ds = MNIST(PATH_DATASETS, train=True, download=True, \n",
    "                 transform=transforms.ToTensor())\n",
    "\n",
    "# 下載測試資料\n",
    "test_ds = MNIST(PATH_DATASETS, train=False, download=True, \n",
    "                 transform=transforms.ToTensor())\n",
    "\n",
    "# 訓練/測試資料的維度\n",
    "print(train_ds.data.shape, test_ds.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練資料前10筆圖片的數字\n",
    "train_ds.targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示第1張圖片內含值\n",
    "train_ds.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000001111111111110000',\n",
       " '0000000011111111111111110000',\n",
       " '0000000111111111111111100000',\n",
       " '0000000111111111110000000000',\n",
       " '0000000011111110110000000000',\n",
       " '0000000001111100000000000000',\n",
       " '0000000000011110000000000000',\n",
       " '0000000000011110000000000000',\n",
       " '0000000000001111110000000000',\n",
       " '0000000000000111111000000000',\n",
       " '0000000000000011111100000000',\n",
       " '0000000000000001111100000000',\n",
       " '0000000000000000011110000000',\n",
       " '0000000000000011111110000000',\n",
       " '0000000000001111111100000000',\n",
       " '0000000000111111111000000000',\n",
       " '0000000011111111110000000000',\n",
       " '0000001111111111000000000000',\n",
       " '0000111111111100000000000000',\n",
       " '0000111111110000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將非0的數字轉為1，顯示第1張圖片\n",
    "data = train_ds.data[0].clone()\n",
    "data[data>0]=1\n",
    "data = data.numpy()\n",
    "\n",
    "# 將轉換後二維內容顯示出來，隱約可以看出數字為 5\n",
    "text_image=[]\n",
    "for i in range(data.shape[0]):\n",
    "    text_image.append(''.join(data[i].astype(str)))\n",
    "text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000001111100000000',\n",
       " '0000000000000011111100000000',\n",
       " '0000000000000111111111000000',\n",
       " '0000000000011111111111000000',\n",
       " '0000000000011111111111000000',\n",
       " '0000000000111111111111000000',\n",
       " '0000000001111111110011100000',\n",
       " '0000000011111100000011100000',\n",
       " '0000000111111100000011100000',\n",
       " '0000000111100000000011100000',\n",
       " '0000000111000000000011100000',\n",
       " '0000001111000000000011100000',\n",
       " '0000001111000000001111100000',\n",
       " '0000001110000000011111000000',\n",
       " '0000001110000000111100000000',\n",
       " '0000001110000001111000000000',\n",
       " '0000001111111111111000000000',\n",
       " '0000001111111111100000000000',\n",
       " '0000001111111110000000000000',\n",
       " '0000000111111100000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將非0的數字轉為1，顯示第2張圖片\n",
    "data = train_ds.data[1].clone()\n",
    "data[data>0]=1\n",
    "data = data.numpy()\n",
    "\n",
    "# 將轉換後二維內容顯示出來，隱約可以看出數字為 5\n",
    "text_image=[]\n",
    "for i in range(data.shape[0]):\n",
    "    text_image.append(''.join(data[i].astype(str)))\n",
    "text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第1張圖片圖像\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 第一筆資料\n",
    "X = train_ds.data[0]\n",
    "\n",
    "# 繪製點陣圖，cmap='gray':灰階\n",
    "plt.imshow(X.reshape(28,28), cmap='gray')\n",
    "\n",
    "# 隱藏刻度\n",
    "plt.axis('off') \n",
    "\n",
    "# 顯示圖形\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟2：資料清理，此步驟無需進行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟3：特徵工程，此步驟無需進行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.data = train_ds.data / 255.0\n",
    "# test_ds.data = test_ds.data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟4：資料分割，此步驟無需進行，載入MNIST資料時，已經切割好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟5：建立模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 * 28, 256), \n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(256, 10), \n",
    "    # 使用nn.CrossEntropyLoss()時，不需要將輸出經過softmax層，否則計算的損失會有誤\n",
    "    # torch.nn.Softmax(dim=1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟6：結合訓練資料及模型，進行模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [    0 / 60000] (0 %)  Loss: 2.299004\n",
      "Epoch 1: [ 6000 / 60000] (10 %)  Loss: 1.999201\n",
      "Epoch 1: [12000 / 60000] (20 %)  Loss: 1.785167\n",
      "Epoch 1: [18000 / 60000] (30 %)  Loss: 1.549837\n",
      "Epoch 1: [24000 / 60000] (40 %)  Loss: 1.336522\n",
      "Epoch 1: [30000 / 60000] (50 %)  Loss: 1.223380\n",
      "Epoch 1: [36000 / 60000] (60 %)  Loss: 0.995878\n",
      "Epoch 1: [42000 / 60000] (70 %)  Loss: 0.974807\n",
      "Epoch 1: [48000 / 60000] (80 %)  Loss: 0.716661\n",
      "Epoch 1: [54000 / 60000] (90 %)  Loss: 0.739871\n",
      "Epoch 2: [    0 / 60000] (0 %)  Loss: 0.694784\n",
      "Epoch 2: [ 6000 / 60000] (10 %)  Loss: 0.549597\n",
      "Epoch 2: [12000 / 60000] (20 %)  Loss: 0.641719\n",
      "Epoch 2: [18000 / 60000] (30 %)  Loss: 0.556501\n",
      "Epoch 2: [24000 / 60000] (40 %)  Loss: 0.570708\n",
      "Epoch 2: [30000 / 60000] (50 %)  Loss: 0.628632\n",
      "Epoch 2: [36000 / 60000] (60 %)  Loss: 0.507579\n",
      "Epoch 2: [42000 / 60000] (70 %)  Loss: 0.616338\n",
      "Epoch 2: [48000 / 60000] (80 %)  Loss: 0.417794\n",
      "Epoch 2: [54000 / 60000] (90 %)  Loss: 0.462503\n",
      "Epoch 3: [    0 / 60000] (0 %)  Loss: 0.463268\n",
      "Epoch 3: [ 6000 / 60000] (10 %)  Loss: 0.359369\n",
      "Epoch 3: [12000 / 60000] (20 %)  Loss: 0.484976\n",
      "Epoch 3: [18000 / 60000] (30 %)  Loss: 0.403067\n",
      "Epoch 3: [24000 / 60000] (40 %)  Loss: 0.448889\n",
      "Epoch 3: [30000 / 60000] (50 %)  Loss: 0.493585\n",
      "Epoch 3: [36000 / 60000] (60 %)  Loss: 0.411807\n",
      "Epoch 3: [42000 / 60000] (70 %)  Loss: 0.525292\n",
      "Epoch 3: [48000 / 60000] (80 %)  Loss: 0.346075\n",
      "Epoch 3: [54000 / 60000] (90 %)  Loss: 0.389544\n",
      "Epoch 4: [    0 / 60000] (0 %)  Loss: 0.389473\n",
      "Epoch 4: [ 6000 / 60000] (10 %)  Loss: 0.306619\n",
      "Epoch 4: [12000 / 60000] (20 %)  Loss: 0.427964\n",
      "Epoch 4: [18000 / 60000] (30 %)  Loss: 0.342473\n",
      "Epoch 4: [24000 / 60000] (40 %)  Loss: 0.403770\n",
      "Epoch 4: [30000 / 60000] (50 %)  Loss: 0.428416\n",
      "Epoch 4: [36000 / 60000] (60 %)  Loss: 0.366806\n",
      "Epoch 4: [42000 / 60000] (70 %)  Loss: 0.490061\n",
      "Epoch 4: [48000 / 60000] (80 %)  Loss: 0.306308\n",
      "Epoch 4: [54000 / 60000] (90 %)  Loss: 0.368454\n",
      "Epoch 5: [    0 / 60000] (0 %)  Loss: 0.351175\n",
      "Epoch 5: [ 6000 / 60000] (10 %)  Loss: 0.278793\n",
      "Epoch 5: [12000 / 60000] (20 %)  Loss: 0.424517\n",
      "Epoch 5: [18000 / 60000] (30 %)  Loss: 0.312485\n",
      "Epoch 5: [24000 / 60000] (40 %)  Loss: 0.376299\n",
      "Epoch 5: [30000 / 60000] (50 %)  Loss: 0.389500\n",
      "Epoch 5: [36000 / 60000] (60 %)  Loss: 0.345639\n",
      "Epoch 5: [42000 / 60000] (70 %)  Loss: 0.475405\n",
      "Epoch 5: [48000 / 60000] (80 %)  Loss: 0.293929\n",
      "Epoch 5: [54000 / 60000] (90 %)  Loss: 0.352371\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr=0.1\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=600)\n",
    "\n",
    "# 設定優化器(optimizer)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "loss_list = []    \n",
    "for epoch in range(1, epochs + 1):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "#         if batch_idx == 0 and epoch == 1: print(data[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            loss_list.append(loss.item())\n",
    "            batch = batch_idx * len(data)\n",
    "            data_count = len(train_loader.dataset)\n",
    "            percentage = (100. * batch_idx / len(train_loader))\n",
    "            print(f'Epoch {epoch}: [{batch:5d} / {data_count}] ({percentage:.0f} %)' +\n",
    "                  f'  Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 對訓練過程的損失繪圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a0aecd84c0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_list, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟7：評分(Score Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均損失: 0.0003, 準確率: 9055/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 建立 DataLoader\n",
    "test_loader = DataLoader(test_ds, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        \n",
    "        # 預測\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        \n",
    "        # 正確筆數\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "# 平均損失\n",
    "test_loss /= len(test_loader.dataset)\n",
    "# 顯示測試結果\n",
    "batch = batch_idx * len(data)\n",
    "data_count = len(test_loader.dataset)\n",
    "percentage = 100. * correct / data_count\n",
    "print(f'平均損失: {test_loss:.4f}, 準確率: {correct}/{data_count}' + \n",
    "      f' ({percentage:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實際比對測試資料的前20筆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual    : [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "prediction:  7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4\n"
     ]
    }
   ],
   "source": [
    "# 實際預測 20 筆資料\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        data, target = test_ds[i][0], test_ds[i][1]\n",
    "        data = data.reshape(1, *data.shape).to(device)\n",
    "        output = torch.argmax(model(data), axis=-1)\n",
    "        predictions.append(str(output.item()))\n",
    "\n",
    "# 比對\n",
    "print('actual    :', test_ds.targets[0:20].numpy())\n",
    "print('prediction: ', ' '.join(predictions[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~9預測機率: [[0.01 0.   0.06 0.   0.04 0.01 0.86 0.   0.01 0.  ]]\n",
      "0~9預測機率: [6]\n"
     ]
    }
   ],
   "source": [
    "# 顯示第 9 筆的機率\n",
    "import numpy as np\n",
    "\n",
    "i=8\n",
    "data = test_ds[i][0]\n",
    "data = data.reshape(1, *data.shape).to(device)\n",
    "#print(data.shape)\n",
    "predictions = torch.softmax(model(data), dim=1)\n",
    "print(f'0~9預測機率: {np.around(predictions.cpu().detach().numpy(), 2)}')\n",
    "print(f'0~9預測機率: {np.argmax(predictions.cpu().detach().numpy(), axis=-1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第 9 筆圖像\n",
    "X2 = test_ds[i][0] \n",
    "plt.imshow(X2.reshape(28,28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟8：評估，暫不進行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟9：模型佈署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型存檔\n",
    "torch.save(model, 'model.pt')\n",
    "\n",
    "# 模型載入\n",
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 權重存檔\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# 權重載入\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一層的 state_dict:\n",
      "1.weight \t torch.Size([256, 784])\n",
      "1.bias \t torch.Size([256])\n",
      "3.weight \t torch.Size([10, 256])\n",
      "3.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 顯示每一層的 state_dict 維度\n",
    "print(\"每一層的 state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟10：新資料預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual/prediction: 0 0\n",
      "actual/prediction: 1 1\n",
      "actual/prediction: 2 2\n",
      "actual/prediction: 3 7\n",
      "actual/prediction: 4 4\n",
      "actual/prediction: 5 5\n",
      "actual/prediction: 6 6\n",
      "actual/prediction: 7 1\n",
      "actual/prediction: 8 8\n",
      "actual/prediction: 9 8\n"
     ]
    }
   ],
   "source": [
    "# 使用小畫家，繪製 0~9，實際測試看看\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# 讀取影像並轉為單色\n",
    "for i in range(10):\n",
    "    uploaded_file = f'./myDigits/{i}.png'\n",
    "    image1 = io.imread(uploaded_file, as_gray=True)\n",
    "\n",
    "    # 縮為 (28, 28) 大小的影像\n",
    "    image_resized = resize(image1, (28, 28), anti_aliasing=True)    \n",
    "    X1 = image_resized.reshape(1,28, 28) \n",
    "\n",
    "    # 反轉顏色，顏色0為白色，與 RGB 色碼不同，它的 0 為黑色\n",
    "    X1 = torch.FloatTensor(1.0-X1).to(device)\n",
    "\n",
    "    # 預測\n",
    "    predictions = torch.softmax(model(X1), dim=1)\n",
    "    # print(np.around(predictions.cpu().detach().numpy(), 2))\n",
    "    print(f'actual/prediction: {i} {np.argmax(predictions.detach().cpu().numpy())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他：顯示模型彙總資訊(summary)、繪製圖形顯示模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Flatten(start_dim=1, end_dim=-1)\n",
      "1: Linear(in_features=784, out_features=256, bias=True)\n",
      "2: Dropout(p=0.2, inplace=False)\n",
      "3: Linear(in_features=256, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# 顯示模型的彙總資訊\n",
    "for name, module in model.named_children():\n",
    "    print(f'{name}: {module}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               --                        --\n",
       "├─Flatten: 1-1                           [60000, 784]              --\n",
       "├─Linear: 1-2                            [60000, 256]              200,960\n",
       "├─Dropout: 1-3                           [60000, 256]              --\n",
       "├─Linear: 1-4                            [60000, 10]               2,570\n",
       "==========================================================================================\n",
       "Total params: 203,530\n",
       "Trainable params: 203,530\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 12.21\n",
       "==========================================================================================\n",
       "Input size (MB): 188.16\n",
       "Forward/backward pass size (MB): 127.68\n",
       "Params size (MB): 0.81\n",
       "Estimated Total Size (MB): 316.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, (60000, 28, 28)) # input dimension size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 無法繪製模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
