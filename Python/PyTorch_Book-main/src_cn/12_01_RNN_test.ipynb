{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单的RNN实作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程式参考来源：\n",
    "- https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN\n",
    "- https://pytorch.org/text/stable/vocab.html\n",
    "- https://pytorch.org/text/stable/functional.html#to-tensor\n",
    "- https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入相关套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入层测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2505,  1.4970,  0.7773, -0.8844,  0.8700],\n",
      "         [ 0.5507, -0.6831,  0.0107, -0.4041,  0.6599],\n",
      "         [ 1.0529, -0.1430,  0.7113, -1.0951, -0.0185]],\n",
      "\n",
      "        [[-2.1144, -1.1461,  0.5346,  1.4119, -0.4880],\n",
      "         [-0.4536, -0.7272, -0.0827, -0.7152, -0.0144],\n",
      "         [-1.1321,  0.8856, -0.0487, -0.7464,  0.0360]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor([[0,1,2], [3,4,5]])\n",
    "embeds = nn.Embedding(6, 5) \n",
    "print(embeds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2505,  1.4970,  0.7773, -0.8844,  0.8700],\n",
       "        [ 0.5507, -0.6831,  0.0107, -0.4041,  0.6599],\n",
       "        [ 1.0529, -0.1430,  0.7113, -1.0951, -0.0185],\n",
       "        [-2.1144, -1.1461,  0.5346,  1.4119, -0.4880],\n",
       "        [-0.4536, -0.7272, -0.0827, -0.7152, -0.0144],\n",
       "        [-1.1321,  0.8856, -0.0487, -0.7464,  0.0360]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2907,  0.2514, -1.0432,  0.5131,  2.2346],\n",
      "         [ 0.0395,  0.3973,  0.2307,  1.0515,  0.6651],\n",
      "         [-0.4278, -0.4222, -0.1849,  2.3283,  0.0529]],\n",
      "\n",
      "        [[ 0.5288,  0.4761, -0.1157, -0.7658,  0.2662],\n",
      "         [ 0.1298, -0.6534,  0.4405, -0.5044,  0.1633],\n",
      "         [-1.5434, -0.9046, -0.1215,  2.0839, -0.6903]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor([[1,2,3], [4,5,6]])\n",
    "embeds = nn.Embedding(7, 5) \n",
    "print(embeds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1974, -0.2802, -0.1226, -1.1460, -1.0106],\n",
      "         [ 0.7972, -0.8367,  0.1772,  0.6812, -0.2185],\n",
      "         [ 1.4565, -1.0132,  1.6636,  0.0494, -1.0966]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[ 0.3134,  1.0122, -0.4550, -0.0074, -0.6427],\n",
      "         [ 1.1022, -1.5268, -0.4586,  1.0043, -0.2670]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1974, -0.2802, -0.1226, -1.1460, -1.0106],\n",
       "        [ 0.7972, -0.8367,  0.1772,  0.6812, -0.2185],\n",
       "        [ 1.4565, -1.0132,  1.6636,  0.0494, -1.0966],\n",
       "        [ 0.3134,  1.0122, -0.4550, -0.0074, -0.6427],\n",
       "        [ 1.1022, -1.5268, -0.4586,  1.0043, -0.2670],\n",
       "        [-1.3189, -0.8618,  1.8304, -0.4719,  1.2202]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = nn.Embedding(6, 5) \n",
    "x1 = torch.LongTensor([[0,1,2]])\n",
    "x2 = torch.LongTensor([[3,4]])\n",
    "print(embeds(x1))\n",
    "print(embeds(x2))\n",
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9749, -0.4108,  0.3783, -0.5760,  0.7223],\n",
      "         [-0.3931,  1.4548, -1.4096,  1.6366,  0.5608],\n",
      "         [-0.5268,  1.1778,  0.3954, -0.4554, -1.0281]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[ 0.5586,  0.2118,  0.5157, -0.0731, -1.0896],\n",
      "         [ 0.1027, -0.1333,  0.0766,  0.7858, -1.2786]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[ 0.5586,  0.2118,  0.5157, -0.0731, -1.0896],\n",
      "         [ 0.1027, -0.1333,  0.0766,  0.7858, -1.2786]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9749, -0.4108,  0.3783, -0.5760,  0.7223],\n",
       "        [-0.3931,  1.4548, -1.4096,  1.6366,  0.5608],\n",
       "        [-0.5268,  1.1778,  0.3954, -0.4554, -1.0281],\n",
       "        [ 0.5586,  0.2118,  0.5157, -0.0731, -1.0896],\n",
       "        [ 0.1027, -0.1333,  0.0766,  0.7858, -1.2786],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = nn.Embedding(6, 5, 5) \n",
    "x1 = torch.LongTensor([[0,1,2]])\n",
    "x2 = torch.LongTensor([[3,4]])\n",
    "x3 = torch.LongTensor([[3,4]])\n",
    "print(embeds(x1))\n",
    "print(embeds(x2))\n",
    "print(embeds(x3))\n",
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2347, 0.0490, 0.1800, 0.6384, 0.4259]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 测试资料\n",
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "# 词汇表(vocabulary)含2个单字, 转换为5维的向量\n",
    "embeds = nn.Embedding(2, 5) \n",
    "# 测试 hello\n",
    "lookup_tensor = torch.LongTensor([word_to_ix[\"hello\"]])\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN层测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 10])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5, 3, 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 20]) torch.Size([2, 20])\n"
     ]
    }
   ],
   "source": [
    "# 测试资料\n",
    "input = torch.randn(5, 10)\n",
    "# 建立 RNN 物件\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "# RNN 处理\n",
    "output, hn = rnn(input)\n",
    "# 显示输出及隐藏层的维度\n",
    "print(output.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 20]) torch.Size([2, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "# 测试资料\n",
    "input = torch.randn(5, 4, 10)\n",
    "# 建立 RNN 物件\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "# RNN 处理\n",
    "output, hn = rnn(input)\n",
    "# 显示输出及隐藏层的维度\n",
    "print(output.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20]) torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 测试资料\n",
    "input = torch.randn(5, 3, 10)\n",
    "# 建立 RNN 物件\n",
    "rnn = nn.RNN(10, 20, 2)\n",
    "# 隐藏层的输入\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "# RNN 处理\n",
    "output, hn = rnn(input, h0)\n",
    "# 显示输出及隐藏层的维度\n",
    "print(output.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['could', 'have', 'done', 'better', '.']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "text = 'Could have done better.'        \n",
    "tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词汇表处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "# BOW 统计\n",
    "counter = Counter(tokenizer(text))\n",
    "# 依出现次数降幂排列\n",
    "sorted_by_freq_tuples = sorted(counter.items(), \n",
    "                       key=lambda x: x[1], reverse=True)\n",
    "# 建立词汇字典\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "# 建立词汇表物件，并加一个未知单字(unknown)的索引值\n",
    "vocab_object = torchtext.vocab.vocab(ordered_dict, specials=[\"<unk>\"])\n",
    "# 设定词汇表预设值为未知单字(unknown)的索引值\n",
    "vocab_object.set_default_index(vocab_object[\"<unk>\"])\n",
    "\n",
    "# 测试\n",
    "vocab_object['done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'could', 'have', 'done', 'better', '.']"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_object.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_object.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def create_vocabulary(text_list):\n",
    "    # 取得标点符号\n",
    "    stopwords = list(string.punctuation)\n",
    "    \n",
    "    # 去除标点符号\n",
    "    clean_text_list = []\n",
    "    clean_tokens_list = []\n",
    "    for text in text_list:\n",
    "        tokens = tokenizer(text) \n",
    "        clean_tokens = []\n",
    "        for w in tokens:\n",
    "            if w not in stopwords:\n",
    "                clean_tokens.append(w)\n",
    "        clean_tokens_list += clean_tokens\n",
    "        clean_text_list.append(' '.join(clean_tokens)) \n",
    "        \n",
    "    # 建立词汇表物件\n",
    "    counter = Counter(clean_tokens_list)    \n",
    "    sorted_by_freq_tuples = sorted(counter.items(), \n",
    "                                   key=lambda x: x[1], reverse=True)\n",
    "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "    vocab_object = torchtext.vocab.vocab(ordered_dict, specials=[\"<unk>\"])\n",
    "    vocab_object.set_default_index(vocab_object[\"<unk>\"])\n",
    "    \n",
    "    # 将输入字串转为索引值：自词汇表物件查询索引值\n",
    "    clean_index_list = []\n",
    "    for clean_tokens_list in clean_text_list:\n",
    "        clean_index_list.append(\n",
    "            vocab_object.lookup_indices(clean_tokens_list.split(' ')))\n",
    "    \n",
    "    # 输出 词汇表物件、去除标点符号的字串阵列、字串阵列的索引值\n",
    "    return vocab_object, clean_text_list, clean_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'work',\n",
       " 'done',\n",
       " 'good',\n",
       " 'effort',\n",
       " 'poor',\n",
       " 'well',\n",
       " 'great',\n",
       " 'nice',\n",
       " 'excellent',\n",
       " 'weak',\n",
       " 'not',\n",
       " 'could',\n",
       " 'have',\n",
       " 'better']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "\n",
    "vocab_object, clean_text_list, clean_index_list = create_vocabulary(docs)\n",
    "vocab_object.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well done',\n",
       " 'good work',\n",
       " 'great effort',\n",
       " 'nice work',\n",
       " 'excellent',\n",
       " 'weak',\n",
       " 'poor effort',\n",
       " 'not good',\n",
       " 'poor work',\n",
       " 'could have done better']"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 2],\n",
       " [3, 1],\n",
       " [7, 4],\n",
       " [8, 1],\n",
       " [9],\n",
       " [10],\n",
       " [5, 4],\n",
       " [11, 3],\n",
       " [5, 1],\n",
       " [12, 13, 2, 14]]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整合以上功能，实作一个简单的案例，说明相关的处理程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立词汇表：整理输入语句，截长补短，使语句长度一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  2,  0,  0],\n",
       "        [ 3,  1,  0,  0],\n",
       "        [ 7,  4,  0,  0],\n",
       "        [ 8,  1,  0,  0],\n",
       "        [ 9,  0,  0,  0],\n",
       "        [10,  0,  0,  0],\n",
       "        [ 5,  4,  0,  0],\n",
       "        [11,  3,  0,  0],\n",
       "        [ 5,  1,  0,  0],\n",
       "        [12, 13,  2, 14]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 4      # 语句最大字数\n",
    "# 测试资料\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better']\n",
    "\n",
    "vocab_object, clean_text_list, clean_index_list = create_vocabulary(docs)\n",
    "\n",
    "# 若字串过长，删除多余单字\n",
    "clean_index_list = torchtext.functional.truncate(clean_index_list, maxlen)\n",
    "\n",
    "# 若字串长度不足，后面补 0\n",
    "while len(clean_index_list[0]) < maxlen:\n",
    "    clean_index_list[0] += [0]\n",
    "torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足补0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入层转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "embeds = nn.Embedding(vocab_object.__len__(), 5) \n",
    "X = torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足补0\n",
    "embed_output = embeds(X)\n",
    "print(embed_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加上完全连接层(Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim * maxlen, num_class) # 要乘以 maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        out = embedded.reshape(embedded.size(0), -1) # 转换成1维\n",
    "        return self.fc(out)\n",
    "\n",
    "model = RecurrentNet(vocab_object.__len__(), 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 另一种写法，使用EmbeddingBag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "model = RecurrentNet(vocab_object.__len__(), 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.72728\n",
      "Epoch: 100, loss: 0.06390\n",
      "Epoch: 200, loss: 0.00598\n",
      "Epoch: 300, loss: 0.00140\n",
      "Epoch: 400, loss: 0.00052\n",
      "Epoch: 500, loss: 0.00016\n",
      "Epoch: 600, loss: 0.00004\n",
      "Epoch: 700, loss: 0.00001\n",
      "Epoch: 800, loss: 0.00000\n",
      "Epoch: 900, loss: 0.00000\n"
     ]
    }
   ],
   "source": [
    "# 定义 10 个语句的正面(1)或负面(0)的情绪\n",
    "y = torch.FloatTensor([1,1,1,1,1,0,0,0,0,0])\n",
    "X = torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足补0\n",
    "\n",
    "# 指定优化器、损失函数\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 模型训练\n",
    "for epoch in range(1000):\n",
    "    outputs = model.forward(X) #forward pass\n",
    "    optimizer.zero_grad() \n",
    "    loss = criterion(outputs.reshape(-1), y)\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    if epoch % 100 == 0:\n",
    "        #print(outputs.shape)\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():1.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 训练资料预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00],\n",
       "        [ 9.9983e-01],\n",
       "        [ 1.0002e+00],\n",
       "        [ 9.9990e-01],\n",
       "        [ 1.0000e+00],\n",
       "        [-3.0272e-05],\n",
       "        [-3.2104e-04],\n",
       "        [ 1.9193e-05],\n",
       "        [ 3.5113e-04],\n",
       "        [-7.1526e-07]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试资料预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0002e+00],\n",
       "        [ 1.0000e+00],\n",
       "        [-3.2104e-04]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试资料\n",
    "test_docs = ['great effort', 'well done',\n",
    "        'poor effort']\n",
    "\n",
    "# 转成数值 \n",
    "clean_index_list = []\n",
    "for text in test_docs:\n",
    "    clean_index_list.append(vocab_object.lookup_indices(text.split(' ')))\n",
    "while len(clean_index_list[0]) < maxlen:\n",
    "    clean_index_list[0] += [0]\n",
    "\n",
    "clean_index_list = torchtext.functional.truncate(clean_index_list, maxlen)    \n",
    "X = torchtext.functional.to_tensor(clean_index_list, 0) # 0:不足补0\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用词向量(Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取 GloVe 50维的词向量，转换为GloVe 50维的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0266,  1.3357, -1.0280, -0.3729,  0.5201, -0.1270, -0.3543,  0.3782,\n",
       "         -0.2972,  0.0939, -0.0341,  0.9296, -0.1402, -0.6330,  0.0208, -0.2153,\n",
       "          0.9692,  0.4765, -1.0039, -0.2401, -0.3632, -0.0048, -0.5148, -0.4626,\n",
       "          1.2447, -1.8316, -1.5581, -0.3747,  0.5336,  0.2088,  3.2209,  0.6455,\n",
       "          0.3744, -0.1766, -0.0242,  0.3379, -0.4190,  0.4008, -0.1145,  0.0512,\n",
       "         -0.1521,  0.2986, -0.4405,  0.1109, -0.2463,  0.6625, -0.2695, -0.4966,\n",
       "         -0.4162, -0.2549]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/text/stable/vocab.html#glove\n",
    "examples = ['great']\n",
    "vec = torchtext.vocab.GloVe(name='6B', dim=50)\n",
    "ret = vec.get_vecs_by_tokens(examples, lower_case_backup=True)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400000, 50])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.stoi['great']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding 不需训练，直接设定嵌入层权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RecurrentNet(nn.Module):\n",
    "    def __init__(self, weights_matrix, num_embeddings, embedding_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(num_embeddings, embedding_dim)\n",
    "        # 设定嵌入层权重\n",
    "        self.embedding.load_state_dict({'weight': weights_matrix})\n",
    "        self.fc = nn.Linear(embedding_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试资料转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better']\n",
    "\n",
    "# 将词汇表转为词向量\n",
    "clean_text_list = []\n",
    "clean_tokens_list = []\n",
    "for i, text in enumerate(docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            clean_tokens.append(w)\n",
    "    clean_tokens_list += clean_tokens   \n",
    "    clean_text_list.append(clean_tokens)  \n",
    "    tokens_vec = vec.get_vecs_by_tokens(clean_tokens)\n",
    "vocab_list = list(set(clean_tokens_list))            \n",
    "weights_matrix = vec.get_vecs_by_tokens(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  6,  0,  0],\n",
       "        [10,  4,  0,  0],\n",
       "        [13, 12,  0,  0],\n",
       "        [ 0,  4,  0,  0],\n",
       "        [ 7,  0,  0,  0],\n",
       "        [ 8,  0,  0,  0],\n",
       "        [ 2, 12,  0,  0],\n",
       "        [ 5, 10,  0,  0],\n",
       "        [ 2,  4,  0,  0],\n",
       "        [ 3, 11,  6,  1]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义 10 个语句的正面(1)或负面(0)的情绪\n",
    "y = torch.FloatTensor([1,1,1,1,1,0,0,0,0,0])\n",
    "X = torch.LongTensor(np.zeros((len(docs), maxlen)))\n",
    "for i, item in enumerate(clean_text_list):\n",
    "    for j, token in enumerate(item):\n",
    "        if token in vocab_list:\n",
    "            X[i, j] = vocab_list.index(token)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nice',\n",
       " 'better',\n",
       " 'poor',\n",
       " 'could',\n",
       " 'work',\n",
       " 'not',\n",
       " 'done',\n",
       " 'excellent',\n",
       " 'weak',\n",
       " 'well',\n",
       " 'good',\n",
       " 'have',\n",
       " 'effort',\n",
       " 'great']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.03547\n",
      "Epoch: 100, loss: 0.09790\n",
      "Epoch: 200, loss: 0.02937\n",
      "Epoch: 300, loss: 0.00643\n",
      "Epoch: 400, loss: 0.00280\n",
      "Epoch: 500, loss: 0.00141\n",
      "Epoch: 600, loss: 0.00067\n",
      "Epoch: 700, loss: 0.00031\n",
      "Epoch: 800, loss: 0.00013\n",
      "Epoch: 900, loss: 0.00006\n"
     ]
    }
   ],
   "source": [
    "# 建立模型物件\n",
    "model = RecurrentNet(torch.FloatTensor(weights_matrix), len(vocab_list), 50, 1)\n",
    "\n",
    "# 指定优化器、损失函数\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 模型训练\n",
    "for epoch in range(1000):\n",
    "    outputs = model.forward(X) #forward pass\n",
    "    optimizer.zero_grad() \n",
    "    loss = criterion(outputs.reshape(-1), y)\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    if epoch % 100 == 0:\n",
    "        #print(outputs.shape)\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():1.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 训练资料预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0005e+00],\n",
       "        [ 1.0003e+00],\n",
       "        [ 1.0043e+00],\n",
       "        [ 9.9065e-01],\n",
       "        [ 1.0017e+00],\n",
       "        [ 1.3793e-03],\n",
       "        [-6.5045e-03],\n",
       "        [-4.8908e-05],\n",
       "        [ 9.2722e-03],\n",
       "        [-1.0637e-04]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0043],\n",
       "        [ 1.0005],\n",
       "        [-0.0065]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试资料\n",
    "test_docs = ['great effort', 'well done',\n",
    "        'poor effort']\n",
    "\n",
    "# 转成数值 \n",
    "X = torch.LongTensor(np.zeros((len(test_docs), maxlen)))\n",
    "clean_text_list = []\n",
    "for i, text in enumerate(test_docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            clean_tokens.append(w)\n",
    "    clean_text_list.append(clean_tokens)  \n",
    "\n",
    "for i, item in enumerate(clean_text_list):\n",
    "    for j, token in enumerate(item):\n",
    "        if token in vocab_list:\n",
    "            X[i, j] = vocab_list.index(token)\n",
    "\n",
    "# 预测            \n",
    "model.eval()        \n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将整个词向量设定为嵌入层权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNet2(nn.Module):\n",
    "    def __init__(self, vec, embedding_dim, num_class):\n",
    "        super().__init__()\n",
    "        # 将整个词向量设定为嵌入层权重，且嵌入层设为不训练\n",
    "        self.embedding = nn.EmbeddingBag.from_pretrained(vec, freeze=True)\n",
    "        self.fc = nn.Linear(embedding_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)\n",
    "    \n",
    "model = RecurrentNet2(vec.vectors, vec.dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 143,  751,    0,    0],\n",
       "        [ 219,  161,    0,    0],\n",
       "        [ 353,  968,    0,    0],\n",
       "        [3082,  161,    0,    0],\n",
       "        [4345,    0,    0,    0],\n",
       "        [2690,    0,    0,    0],\n",
       "        [ 992,  968,    0,    0],\n",
       "        [  36,  219,    0,    0],\n",
       "        [ 992,  161,    0,    0],\n",
       "        [  94,   33,  751,  439]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试资料\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better']\n",
    "\n",
    "# 转成数值 \n",
    "X = torch.LongTensor(np.zeros((len(docs), maxlen)))\n",
    "\n",
    "for i, text in enumerate(docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    j=0\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            # 转成词向量索引值 \n",
    "            X[i, j] = vec.stoi[w]\n",
    "            j+=1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.26617\n",
      "Epoch: 100, loss: 0.12657\n",
      "Epoch: 200, loss: 0.07799\n",
      "Epoch: 300, loss: 0.05655\n",
      "Epoch: 400, loss: 0.04253\n",
      "Epoch: 500, loss: 0.03269\n",
      "Epoch: 600, loss: 0.02547\n",
      "Epoch: 700, loss: 0.01998\n",
      "Epoch: 800, loss: 0.01569\n",
      "Epoch: 900, loss: 0.01227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8730],\n",
       "        [ 0.9340],\n",
       "        [ 1.0150],\n",
       "        [ 0.9696],\n",
       "        [ 0.9747],\n",
       "        [-0.0099],\n",
       "        [-0.0561],\n",
       "        [ 0.2156],\n",
       "        [ 0.1366],\n",
       "        [-0.0677]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定优化器、损失函数\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 模型训练\n",
    "for epoch in range(1000):\n",
    "    outputs = model.forward(X) #forward pass\n",
    "    optimizer.zero_grad() \n",
    "    loss = criterion(outputs.reshape(-1), y)\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    if epoch % 100 == 0:\n",
    "        #print(outputs.shape)\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():1.5f}\")\n",
    "\n",
    "model.eval()        \n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 输入训练数据以外的单字测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[353, 664,   0,   0],\n",
       "        [143, 751,   0,   0],\n",
       "        [992, 664,   0,   0]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试资料\n",
    "test_docs = ['great job', 'well done',\n",
    "        'poor job']\n",
    "\n",
    "# 转成数值 \n",
    "X = torch.LongTensor(np.zeros((len(test_docs), maxlen)))\n",
    "for i, text in enumerate(test_docs):\n",
    "    tokens = tokenizer(text.lower()) \n",
    "    clean_tokens = []\n",
    "    j=0\n",
    "    for w in tokens:\n",
    "        if w not in stopwords:\n",
    "            X[i, j] = vec.stoi[w]\n",
    "            j+=1\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## 训练资料预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6623],\n",
       "        [ 0.8730],\n",
       "        [-0.4088]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()        \n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
