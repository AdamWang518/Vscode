{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/usuyama/pytorch-unet/blob/master/pytorch_unet_resnet18_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4lcY1ziTLblo"
   },
   "source": [
    "## pytorch-uent\n",
    "\n",
    "https://github.com/usuyama/pytorch-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "yUvckFGU-4HE",
    "outputId": "b7c6934b-b2a7-4654-aa03-955576b2fb29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-unet'...\n",
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 64 (delta 4), reused 0 (delta 0), pack-reused 55\u001b[K\n",
      "Unpacking objects: 100% (64/64), done.\n",
      "/content/pytorch-unet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"pytorch_unet\"):\n",
    "    !git clone https://github.com/usuyama/pytorch-unet.git\n",
    "\n",
    "%cd pytorch-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "EAx84Zg1_RnV",
    "outputId": "b96f12d2-dd61-4d5e-e4be-9446fb645b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper.py  pytorch_fcn.ipynb\t\tpytorch_unet_resnet18_colab.ipynb\n",
      "images\t   pytorch_resnet18_unet.ipynb\tREADME.md\n",
      "LICENSE    pytorch_unet.ipynb\t\tsimulation.py\n",
      "loss.py    pytorch_unet.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N90-BlegJZfs"
   },
   "source": [
    "## Enabling GPU on Colab\n",
    "\n",
    "Need to enable GPU from Notebook settings\n",
    "\n",
    "- Navigate to Edit-Notebook settings menu\n",
    "- Select GPU from the Hardware Accelerator dropdown list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HCitpQdkJNdI",
    "outputId": "541fd863-67b2-460a-dc18-212606460569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
    "\n",
    "print(\"device name\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8nZ6_mKMsJs"
   },
   "source": [
    "## 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6qt0VHVZ_53z",
    "outputId": "f065f339-e427-4778-dcb6-9ce047f1958b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation # simulation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8nZ6_mKMsJs"
   },
   "source": [
    "## 測試 simulation.py 生成的圖像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6qt0VHVZ_53z",
    "outputId": "f065f339-e427-4778-dcb6-9ce047f1958b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_images shape and range (3, 192, 192, 3) 0 255\n",
      "target_masks shape and range (3, 6, 192, 192) 0.0 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAKvCAYAAAAiIWV+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzfElEQVR4nO3df4xkZZ3v8c+nh9U/gI0gtZNxoHfAHfWCWVrtjIYVg+IPIIsIJOxMNjoquT3kQrLumuzFJbmS3bgxriyJcUWbMAFudIBdQFkzu8olRsIGVnp0HAcEmUEIM4wzLRjxV9CZ/t4/+hQeeqq6quucp8+Pfr+SSp166lSdb/XMcz71nDo/HBECAADpjFVdAAAAbUfYAgCQGGELAEBihC0AAIkRtgAAJEbYAgCQWLKwtX2e7cdt77F9darlAABQd05xnK3tVZJ+JOk9kvZJeljSpoh4tPSFAQBQc6lGthsk7YmIJyPit5Juk3RRomUBAFBrxyR637WSnsk93ifprf1mts1prLCS/TQiOlUXUZaTTjop1q1bV3UZQCV27NjRsz+nCtuBbE9Jmqpq+UCNPF11AUXl+/P4+LhmZmYqrgiohu2e/TnVZuT9kk7JPT45a3tJRExHxGRETCaqAcAyyffnTqc1g3SgNKnC9mFJ622favsVkjZKuifRsgAAqLUkm5Ej4rDtqyR9Q9IqSVsj4pEUywIAoO6S/WYbEdslbU/1/gAANAVnkAIAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBoMVSXEYVS0fY4ihzc3NVlwCgBBGhsekLCdwaIGxxFNsELtAiBG71CFv0ROAC7ULgVouwRV8ELtAuBG51CFssisAF2oXArQZhi4EIXKBdCNzlR9hiKAQu0C4E7vIibDE0AhdoFwJ3+YwctrZPsf0t24/afsT2X2Xt19reb3tndrugvHJRNQIXaBcCd3kUGdkelvTxiDhd0tskXWn79Oy56yNiIrttL1wlaoXABdqFwE1v5LCNiAMR8d1s+heSfihpbVmFod4IXKBdCNy0SvnN1vY6SW+S9N9Z01W2d9neavuEMpaB+iFwUXcRMfJtJSJw0zmm6BvYPk7SnZI+FhEv2L5B0j9Iiuz+Okkf7fG6KUlTRZePanUDd2yMfe1Wsnx/Hh8fr7iaeRGhs/7kH0d+/YN7rymxmuYYm75Qc1P/LttVl9IqhdaQtv9A80H75Yi4S5Ii4mBEHImIOUk3StrQ67URMR0RkxExWaSGsnVHaqPer0SMcJHvz51Op+pyUBAj3PIV2RvZkm6S9MOI+Odc+5rcbBdL2j16ecuvO0Ib9X6lInCBdiFwy1UkIf5M0gclvWvBYT6fsf0D27skvVPSX5dR6HJhZDs6AhdoFwK3PCP/ZhsRD0jqtVG/0Yf6MLItht9wgXbhN9xysEZcgJFtcYxwgXZhhFscYbsAI9tyELhAuxC4xZAQCzCyLQ+BC7QLgTs6wnYBRrbFTgTQ68QABC7QHmPTF1ZdQiMVPqlF23R37hn1vg3a8jmAqnS/aFa9U5FtxZavV1oD5rFWXaCqkW1EMAIEWiAidOsDZ+nWB86quhTUCGG7AL/ZAgDKRtguwG+2AICykRALMLIFAJSNsF2AkS0AoGzsjQyglWyv2MvkoX4IWwAYwTAnd1hsnqoPC8LyImyX0aDOabvvPBHBpmqgJrqH9wyy2Dybz36wzJJQc4TtMhrmWy6nQgOA9iFsl9FiI9Pu6Q0ZvQL1Z7vvyDQ/6mX0ii7W7AAAJFZ4ZGv7KUm/kHRE0uGImLR9oqTbJa2T9JSkyyLiZ0WXBQBAE5U1sn1nRExExGT2+GpJ90XEekn3ZY8BAFiRUm1GvkjSLdn0LZI+kGg5AADUXhlhG5K+aXuH7amsbXVEHMimfyJpdQnLAYDKDHv9ZqCXMvZGfntE7Lf9R5Lutf1Y/smICNtH/S/MgnlqYXubDOp8+b2P6ahosnx/Hh8fr7ia8kWEHn77uwbOt+G/vrUM1aCJCodtROzP7g/ZvlvSBkkHba+JiAO210g61ON105KmJalXGK80HPKDJsv358nJyRXdnxc7LAgrV6E1vO1jbR/fnZb0Xkm7Jd0jaXM222ZJXyuyHAAAmqzoyHa1pLuzsx8dI+krEfGfth+WdIftyyU9LemygssBAKCxCoVtRDwp6cwe7c9JOrfIewMA0Bb8UAgAQGKELQAAiRG2AAAkxlV/EuLYWQCARNgmxbGzQDvY5oQVKIQ0AAAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIb+dzItl8v6fZc02mS/o+kV0n6n5Jms/a/i4jtoy4HAICmGzlsI+JxSROSZHuVpP2S7pb0EUnXR8RnyygQAICmK2sz8rmS9kbE0yW9HwAArVFW2G6UtC33+Crbu2xvtX1CScsAAKCRCoet7VdIer+kf82abpD0Ws1vYj4g6bo+r5uyPWN7pmgNAKqV78+zs7ODXwCsMGWMbM+X9N2IOChJEXEwIo5ExJykGyVt6PWiiJiOiMmImCyhBgAVyvfnTqdTdTlA7ZQRtpuU24Rse03uuYsl7S5hGQAANNbIeyNLku1jJb1H0pZc82dsT0gKSU8teA4AgBWnUNhGxK8kvXpB2wcLVQQAQMtwBikAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDEhgpb21ttH7K9O9d2ou17bT+R3Z+Qtdv252zvsb3L9ptTFQ8AQBMMO7K9WdJ5C9qulnRfRKyXdF/2WJLOl7Q+u01JuqF4mQAANNdQYRsR90t6fkHzRZJuyaZvkfSBXPutMe8hSa+yvaaEWgEAaKQiv9mujogD2fRPJK3OptdKeiY3376sDQCAFamUHaQiIiTFUl5je8r2jO2ZMmoAUJ18f56dna26HKB2ioTtwe7m4ez+UNa+X9IpuflOztpeJiKmI2IyIiYL1ACgBvL9udPpVF0OUDtFwvYeSZuz6c2SvpZr/1C2V/LbJP08t7kZAIAV55hhZrK9TdI5kk6yvU/SJyV9WtIdti+X9LSky7LZt0u6QNIeSb+W9JGSawYAoFGGCtuI2NTnqXN7zBuSrixSFAAAbcIZpAAASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASGyoM0gBAOpj/kR9i7O9DJVgWITtCjGoc0aExsbY0AHUWbcfb7nr2YHzfumS10gidOuCsG25Yb4BS/MdMiIIXaCmImKokO3qzvulS15D4NYAa9UWWxi03TDtdeuyrbm5ueUuFcAilhq0eVvuenboL91Ih5FtS/UK2sVGrHNzcy99++0GLiNcoHr9gnb60rVDz7/lrmcZ4VaMtWkLLTVoJWlsbIwRLlAzSw1aab7vdn+vzRt1ZIxyELYtt5TfYBcGLoD6WSxou/oFLv27OgPXwra32j5ke3eu7Z9sP2Z7l+27bb8qa19n+ze2d2a3LyasHT3kO9MoOzvlA5fRLVCdXqPaYYK2q1fgMrqtzjBr4pslnbeg7V5Jb4yIP5X0I0mfyD23NyImstsV5ZSJpSqyVzG/1QL1s5Sg7eo3wsXyG7hWjYj7JT2/oO2bEXE4e/iQpJMT1AYAQCuUMYT5qKT/yD0+1fb3bH/b9tklvD8AAI1W6NAf29dIOizpy1nTAUnjEfGc7bdI+qrtMyLihR6vnZI0VWT5AOoh35/Hx8crrgaon5FHtrY/LOnPJf1lZHvURMSLEfFcNr1D0l5Jr+v1+oiYjojJiJgctQYA9ZDvz51Op+pygNoZKWxtnyfpbyW9PyJ+nWvv2F6VTZ8mab2kJ8soFACAphq4Gdn2NknnSDrJ9j5Jn9T83sevlHRvdkaSh7I9j98h6e9t/07SnKQrIuL5nm8MABhaRHAGqAYbGLYRsalH80195r1T0p1Fi8Louh2yyCkXOfAdqJ9RTrlY5JzKKBcHVLZMPlxHOSlF0ZNiAChHv5NSDPtluOhJMVAu1qQtNOo5jhnRAvU3TOAyoq0fwraFRrmowCgXLwCQ1mIXFVjskplLvXgB0uMSey01NjZ21GXzlrL5iaAF6qEbuL0umzcsgrZ6rFFbrDvCXUrIErRA/RQ5xzFBWw+MbFuuG5zD/G5LyAL1ZVvTl64d+vdYQrZeCNsVgiBFGyy2lWalHIPaDV00S+vDtl/nZHMp0CwRoV9+f1Xf548788iKCVw0T6vTZtC3YC6MDjTDoKCVpF9+fxWHr6G2Whu2w3Q6Aheov2GCtmvY+YDl1tqwBQCgLghbAAASI2wBAEiMsAUAIDHCFgCAxFobthwCAACoi4Fha3ur7UO2d+farrW93/bO7HZB7rlP2N5j+3Hb70tV+CALr3zTCye2AOrPto4788hQ8x4/waF8qKdhkuZmSef1aL8+Iiay23ZJsn26pI2Szshe8wXblR34lj8Rf68bQQs0wzCBS9CizgaerjEi7re9bsj3u0jSbRHxoqQf294jaYOkB0cvsRgCFWgH2wQqGqtIEl1le1e2mfmErG2tpGdy8+zL2gAAWLFGDdsbJL1W0oSkA5KuW+ob2J6yPWN7ZsQaANREvj/Pzs5WXQ5QOyOFbUQcjIgjETEn6UbNbyqWpP2STsnNenLW1us9piNiMiImR6kBQH3k+3On06m6HKB2Rgpb22tyDy+W1N1T+R5JG22/0vapktZL+k6xEgEAaLaBO0jZ3ibpHEkn2d4n6ZOSzrE9ISkkPSVpiyRFxCO275D0qKTDkq6MiOH22QcAoKWG2Rt5U4/mmxaZ/1OSPlWkKAAA2oTjYgAASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIbGLa2t9o+ZHt3ru122zuz21O2d2bt62z/JvfcFxPWDgBAIxwzxDw3S/q8pFu7DRHxF91p29dJ+nlu/r0RMVFSfQAANN7AsI2I+22v6/WcbUu6TNK7Sq4LAIDWKPqb7dmSDkbEE7m2U21/z/a3bZ9d8P0BAGi8YTYjL2aTpG25xwckjUfEc7bfIumrts+IiBcWvtD2lKSpgssHUAP5/jw+Pl5xNUD9jDyytX2MpEsk3d5ti4gXI+K5bHqHpL2SXtfr9RExHRGTETE5ag0A6iHfnzudTtXlALVTZDPyuyU9FhH7ug22O7ZXZdOnSVov6cliJQIA0GzDHPqzTdKDkl5ve5/ty7OnNurlm5Al6R2SdmWHAv2bpCsi4vkS6wUAoHGG2Rt5U5/2D/dou1PSncXLAgCgPTiDFAAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJCYI6LqGmR7VtKvJP206lpKcJL4HHXShM/xxxHRmuvS2f6FpMerrqMETfi/Mww+x/Lq2Z9rEbaSZHumDde25XPUS1s+R5O05W/O56iXpn8ONiMDAJAYYQsAQGJ1CtvpqgsoCZ+jXtryOZqkLX9zPke9NPpz1OY3WwAA2qpOI1sAAFqJsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEgsWdjaPs/247b32L461XIAAKg7R0T5b2qvkvQjSe+RtE/Sw5I2RcSjpS8MAICaSzWy3SBpT0Q8GRG/lXSbpIsSLQsAgFpLFbZrJT2Te7wvawMAYMU5pqoF256SNJU9fEtVdQA18NOI6FRdRBH5/nzssce+5Q1veEPFFQHV2LFjR8/+nCps90s6Jff45KztJRExLWlakmyX/8Mx0BxPV11AUfn+PDk5GTMzMxVXBFTDds/+nGoz8sOS1ts+1fYrJG2UdE+iZQEAUGtJRrYRcdj2VZK+IWmVpK0R8UiKZQEAUHfJfrONiO2Stqd6fwAAmoIzSAEAkBhhCwBAYoQtAACJEbYAACRG2AIAkBhhCwBAYpWdrhEAVqLFrrRmexkrwXIibBugX+eMCI2NsXECaIJuP/7l91f1nee4M49IInTbiLCtsUHXGratiCB0gZqLiEVDtqs7z3FnHiFwW4Y1dE0NCto825qbm0tYDYBRDRu0eUudH/VH2AJADS3lCzfqj7CtoVE6GaNboH5GGdV2MbptF8IWAIDECFsAABIjbAEASIywBQAgsZHD1vYptr9l+1Hbj9j+q6z9Wtv7be/MbheUVy4AAM1T5KQWhyV9PCK+a/t4STts35s9d31EfLZ4eStTRHBAOwC0yMgj24g4EBHfzaZ/IemHktaWVdhKNsrZoDiLFFA/tl86BeNSHT/BoXxtUsra2fY6SW+S9N9Z01W2d9neavuEMpax0nBAOwC0R+GwtX2cpDslfSwiXpB0g6TXSpqQdEDSdX1eN2V7xvZM0RraaGxs7KXzHi+GcyOjDvL9eXZ2tupyamWU0S2j2vZxkRGU7T+Q9HVJ34iIf+7x/DpJX4+INw54H4Zxi1jszFCEbCvsiIjJqosoy+TkZMzM8B26l0FnlCJkm892z/488g5Snt+D5yZJP8wHre01EXEge3ixpN2jLgPzCFSgHWwTqCtUkb2R/0zSByX9wPbOrO3vJG2yPSEpJD0laUuBZQAA0Hgjh21EPCCp1/Ep20cvBwCA9mH7JAAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGIjXzy+y/ZTkn4h6YikwxExaftESbdLWifpKUmXRcTPii4LAIAmKmtk+86ImIiIyezx1ZLui4j1ku7LHgMAsCKl2ox8kaRbsulbJH0g0XIAAKi9MsI2JH3T9g7bU1nb6og4kE3/RNLqEpYDAEAjFf7NVtLbI2K/7T+SdK/tx/JPRkTYjoUvyoJ5amE7gObJ9+fx8fGKqwHqp/DINiL2Z/eHJN0taYOkg7bXSFJ2f6jH66YjYjL3Oy+Ahsr3506nU3U5QO0UClvbx9o+vjst6b2Sdku6R9LmbLbNkr5WZDkAADRZ0c3IqyXdbbv7Xl+JiP+0/bCkO2xfLulpSZcVXA4AAI1VKGwj4klJZ/Zof07SuUXeGwCAtuAMUgAAJEbYAgCQGGELAEBihC0AAIkRtgAAJEbYAgAqEXHUyQVbi7BFo8zNzVVdAoASRITGpi9cMYFL2KJRbBO4QIuslMAlbNE4BO7KFBErYqW8Eq2EwG112EYEK+WWInBXlojQrQ+cpVsfOKvqUpBI2wO31WGLdiNwgXZpc+AStmg0Ahdol7YGLmGLxiNwgXZpY+AStmgFAhdol7YFLmGL1iBwgXZpU+AStmgVAhdol7YE7shha/v1tnfmbi/Y/pjta23vz7VfUGbBwCAEbjN1j6PtdRt2vl4r5UHzL+W9UI02BO4xo74wIh6XNCFJtldJ2i/pbkkfkXR9RHy2jAIH1DBwHtuLzhcRGhsbO6pt1HoWvheq0Q1c/j2aoXsc7TAGzbf57Adf9r4Pv/1dI9e14b++NfJrUa6x6Qs1N/Xvsl11KSMpa010rqS9EfF0Se83lGG/lfLNtT2WOiphhAu0x9j0hVWXMLKRR7YLbJS0Lff4KtsfkjQj6eMR8bOSlvMyg0Yt3ZUuo5v24N+ynWy/bES6UH7ku9h8aA7bii1fr7qMZVN4zWX7FZLeL+lfs6YbJL1W85uYD0i6rs/rpmzP2J4pWgOAauX78+zsbNXlALVTxjDhfEnfjYiDkhQRByPiSETMSbpR0oZeL4qI6YiYjIjJEmoAUKF8f+50OlWXA9ROGWG7SblNyLbX5J67WNLuEpYBAEBjFfrN1vaxkt4jaUuu+TO2JySFpKcWPAcAwIpTKGwj4leSXr2g7YOFKgIAoGXYtRMAgMRaHbYcRwsAqIOyjrOtJY7JBNph0HG4QN2RRgAAJEbYAgCQGGELAEBirf7NdlTsWAUAKBNh2wM7VgHtYJvL5KEWSBUAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDEhgpb21ttH7K9O9d2ou17bT+R3Z+Qtdv252zvsb3L9ptTFQ8AZYuIwjdgoWHPIHWzpM9LujXXdrWk+yLi07avzh7/b0nnS1qf3d4q6YbsvtXm5uY0NjY28j2A6kWEzvqTfyz8Pg/uvaaEatAmQ63lI+J+Sc8vaL5I0i3Z9C2SPpBrvzXmPSTpVbbXlFBrrXUDc9R7AEB7FVnTr46IA9n0TyStzqbXSnomN9++rK3V5ubmCt0DANqrlGFVzP9IsaQfKmxP2Z6xPVNGDVVjZIuVLN+fZ2dnqy4HqJ0ia/qD3c3D2f2hrH2/pFNy852ctb1MRExHxGRETBaooTYY2WIly/fnTqdTdTlA7RQJ23skbc6mN0v6Wq79Q9leyW+T9PPc5ubWYmQLAOhn2EN/tkl6UNLrbe+zfbmkT0t6j+0nJL07eyxJ2yU9KWmPpBsl/a/Sq64hRrYAgH6GOvQnIjb1eercHvOGpCuLFNVEjGwBAP2wpi8JI1sAQD+EbUkY2QIA+mFNXxJGtgCAfgjbkjCyBQD0w5q+JIxsAQD9ELYlYWQLAOiHNX1JGNkCAPohbEvCyBYA0A9r+pIwsgUA9DPsxeMxACNboPlsc+F3JMGaHgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASGxi2trfaPmR7d67tn2w/ZnuX7bttvyprX2f7N7Z3ZrcvJqwdAIBGGGZke7Ok8xa03SvpjRHxp5J+JOkTuef2RsREdruinDIBAGiugWEbEfdLen5B2zcj4nD28CFJJyeoDQCAVijjN9uPSvqP3ONTbX/P9rdtn13C+wMA0GiFTtdo+xpJhyV9OWs6IGk8Ip6z/RZJX7V9RkS80OO1U5KmiiwfQD3k+/P4+HjF1QD1M/LI1vaHJf25pL+MiJCkiHgxIp7LpndI2ivpdb1eHxHTETEZEZOj1gCgHvL9udPpVF0OUDsjha3t8yT9raT3R8Svc+0d26uy6dMkrZf0ZBmFAgDQVAM3I9veJukcSSfZ3ifpk5rf+/iVku61LUkPZXsev0PS39v+naQ5SVdExPM93xgAgBViYNhGxKYezTf1mfdOSXcWLQoAgDbhDFIAACRG2AIAkBhhCwBAYoQtAACJEbYAACRG2AIAkBhhCwBAYoQtAACJEbYAACRG2AIAkBhhCwBAYoWuZwsAbZFdKXRR2YVXgCUjbAsY1DkjQmNjbDwA6i4itOWuZwfO96VLXkPgYiQkwYgWBm1EvHTrsq25ubnlLg3AEgwbtJK05a5nhxoBAwsxsh1BvrN1p/Mj2G7A2n4pcBnhAvXTL2inL13b9/ktdz3LCBdLRgIs0cKgHRsbOypIu23deRnhAvXTK0inL137UtBK8313+tK1+tIlr3nZfIxwsVQDw9b2VtuHbO/OtV1re7/tndntgtxzn7C9x/bjtt+XqvAq9AraxRC4QD31C9p+bPcMXGBYw4xsb5Z0Xo/26yNiIrttlyTbp0vaKOmM7DVfsL2qrGLrYik7PrH5GKi/xYK2q1fgAsMamAQRcb+k54d8v4sk3RYRL0bEjyXtkbShQH2twOYmAFjZigy7rrK9K9vMfELWtlbSM7l59mVtrTHK4TyMboH6GmZU28XoFqMaNQVukPRaSROSDki6bqlvYHvK9oztmRFrAFAT+f48OztbdTlA7YwUthFxMCKORMScpBv1+03F+yWdkpv15Kyt13tMR8RkREyOUgOA+sj3506nU3U5S8LPPFgOI4Wt7TW5hxdL6u6pfI+kjbZfaftUSeslfadYifUyyl7FdGagvpayV/FSToAB5A08qYXtbZLOkXSS7X2SPinpHNsTkkLSU5K2SFJEPGL7DkmPSjos6cqIOJKkcgAoSURwkgokNTBsI2JTj+abFpn/U5I+VaSouup2yKWcFYpRLVB/w5wVilEtimA32SVY6kkqlnoSDADLo99JKhae31z6/XnPl3ISDGAhzo28RGNjY5qbm3tphNvtiPkg7dVZCVqgXrqBmw/R7nQ+iBc7dzIwLMJ2BPnAlfRS6PZC0AL11StwpcV3miJoMQpSYETdTcqDbgQtUG9LOVEFQYtRMbItgCAF2qF7dR8gFdICAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASGxg2NreavuQ7d25tttt78xuT9nembWvs/2b3HNfTFg7AACNMMyFCG6W9HlJt3YbIuIvutO2r5P089z8eyNioqT6AABovIFhGxH3217X6znPX9D1MknvKrkuAABao+hvtmdLOhgRT+TaTrX9Pdvftn12wfcHAKDxil7PdpOkbbnHBySNR8Rztt8i6au2z4iIFxa+0PaUpKmCywdQA/n+PD4+XnE1QP2MPLK1fYykSyTd3m2LiBcj4rlseoekvZJe1+v1ETEdEZMRMTlqDQDqId+fO51O1eUAtVNkM/K7JT0WEfu6DbY7tldl06dJWi/pyWIlAgDQbMMc+rNN0oOSXm97n+3Ls6c26uWbkCXpHZJ2ZYcC/ZukKyLi+RLrBQCgcYbZG3lTn/YP92i7U9KdxcsCAKA9OIMUAACJEbYAACRG2AIAkBhhCwBAYoQtAACJEbYAACRG2AIAkBhhCwBAYoQtAACJEbYAACRG2AIAkBhhCwBAYo6IqmuQ7VlJv5L006prKcFJ4nPUSRM+xx9HRGsuAmv7F5Ier7qOEjTh/84w+BzLq2d/rkXYSpLtmTZcSJ7PUS9t+RxN0pa/OZ+jXpr+OdiMDABAYoQtAACJ1Slsp6suoCR8jnppy+dokrb8zfkc9dLoz1Gb32wBAGirOo1sAQBoJcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgMcIWAIDECFsAABIjbAEASIywBQAgsWRha/s824/b3mP76lTLAQCg7hwR5b+pvUrSjyS9R9I+SQ9L2hQRj5a+MAAAai7VyHaDpD0R8WRE/FbSbZIuSrQsAABq7ZhE77tW0jO5x/skvTU/g+0pSVPZw7ckqgNogp9GRKfqIorI9+djjz32LW94wxsqrgioxo4dO3r251RhO1BETEualiTb5W/LBprj6aoLKCrfnycnJ2NmZqbiioBq2O7Zn1NtRt4v6ZTc45OzNgAAVpxUYfuwpPW2T7X9CkkbJd2TaFkAANRaks3IEXHY9lWSviFplaStEfFIimUBAFB3yX6zjYjtkranen8AAJqCM0gBAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAAZKce3zlYSwRTJzc3NVlwCgBBGhsekLCdwCCFskY5vABVqEwB0dYYukCFygXQjc0RC2SI7ABdqFwF06whbLgsAF2oXAXRrCFsuGwAXahcAdHmGLZUXgAu1C4A5n5LC1fYrtb9l+1PYjtv8qa7/W9n7bO7PbBeWVizYgcIF2IXAHKzKyPSzp4xFxuqS3SbrS9unZc9dHxER22164SrQOgQu0C4G7uJHDNiIORMR3s+lfSPqhpLVlFYb2I3CBdiFw+yvlN1vb6yS9SdJ/Z01X2d5le6vtE/q8Zsr2jO2ZMmpAMxG47ZDvz7Ozs1WXgwoRuL0VDlvbx0m6U9LHIuIFSTdIeq2kCUkHJF3X63URMR0RkxExWbQGNBuB23z5/tzpdKouBxUjcI9WKGxt/4Hmg/bLEXGXJEXEwYg4EhFzkm6UtKF4mWg7AhdoFwL35YrsjWxJN0n6YUT8c659TW62iyXtHr08rCQELtAuBO7vFRnZ/pmkD0p614LDfD5j+we2d0l6p6S/LqNQrAwELtAuBO68Y0Z9YUQ8IMk9nuJQHxTSDdyxMc65ArTB2PSFmpv6d81vEF2ZWJuhlhjhAu2y0ke4hC1qi8AF2mUlBy5hi1ojcIF2WamBS9ii9ghcoF1WYuAStkgmIkq7SSJwgRYZm76w6hKW1ch7IwODsDcx0A62FVu+XnUZjcbaEACAxAhbAAASI2wBAEiM32wBAD2l2GN4pZ5FirBFqbqnWSz7HsDyigid9Sf/WPr7Prj3mtLfswlYi6FU3WAs+x4Amow1GUrVPRa27HsAaDLCFqViZAsAR2NNhlIxsgWAoxG2KBUjWwA4WuE1me2nbP/A9k7bM1nbibbvtf1Edn9C8VLRBIxsAeBoZQ0b3hkRExExmT2+WtJ9EbFe0n3ZY6wAjGwB4Gip1mQXSbolm75F0gcSLQc1w8gWAI5WRtiGpG/a3mF7KmtbHREHsumfSFq98EW2p2zPdDc9ox0Y2a5M+f48OztbdTlA7ZSxJnt7RLxZ0vmSrrT9jvyTMX++r6PO+RUR0xExmdv0jBZgZLsy5ftzp9OpuhygdgqHbUTsz+4PSbpb0gZJB22vkaTs/lDR5aAZGNkCwNEKrclsH2v7+O60pPdK2i3pHkmbs9k2S/pakeWgORjZAsDRil6IYLWku7OrOBwj6SsR8Z+2H5Z0h+3LJT0t6bKCy0FDMLJFWw1zBZyVekUbDFYobCPiSUln9mh/TtK5Rd67DQZ1zohoXZhw1R+0Tbcfb7nr2YHzfumS10gidHE0LrGXwLDXgLStiGhV6DKyRZtExFAh29Wd90uXvIbAxcuwJitZr6DtBmr+lme7Nb9N8pst2mKpQZu35a5nk1x4Hc3FyLZECztX93Gv0Vk3RLrffruB2/SRHCNbtMFiQTt96dqh5t1y17OMcPES1mQl6RW0Y2NjfcOi+1z+dW0Y4TKyRdP1C8/pS9ceFbTSfL+dvnTtS7/X5jHCRRdhW4J+QTuMtgUuI1s02WJBO4jtvoELsCYr2Sg7Oy0M3CZjZIu2GSZou/oFblv6N0bnOvwnsF19ESPK//2K7lVc5nuhUXa06bSlk5OTMTPTvFOe9xrVLiVoU70XmsV2z/7M2rxG6vDFBwBQPsK2JGWMRBnJAvVRZCTab3MyVi7W7gAAJEbYAgCQGGELAEBihC0A9MAOiygTYVuSMk5GQecG6qPIySiKnFcZ7UTYFkRAAu1F/0ZZCNuC8ofrFBndckILoFq9DtcZ5dzGnNACvYy8Rrf9ets7c7cXbH/M9rW29+faLyiz4Doqem5jvj0D9bWUwGXzcTG9Lkfa67KkTVTK6Rptr5K0X9JbJX1E0i8j4rNLeH3j/5Jzc3Mvu5TWsKPTIhcxQP8vKg37O3K6xhrpF5jdUW+vS+Z1/x+OehEDzP8Nf/n9VX2fP+7MI424XGHq0zWeK2lvRDxd0vs1Tq+r90RE31Fur29rDQuIyi32RbHpV09CdRa7ek93lLvw1n1uIYJ2OIOCVpJ++f1VjR7hlnXx+I2StuUeX2X7Q5JmJH08In628AW2pyRNlbT8WhgbGztqhNsN3UEI2qUZ5m/aDVz+runl+/P4+HjF1RTXDdx+F4UfBkE7nGGCtuuX31/VmBHuQoU3I9t+haRnJZ0REQdtr5b0U0kh6R8krYmIjw54j+Z+XemhO6Ia5j9E9+9PIAxvlB1Wav73ZTNyTY36GyxBO5ylBG3e8RP13WrVbzNyGSPb8yV9NyIOSlL3PlvojZK+XsIyGqW7Yh9mM2bNQwBY0Wxr+tK1Q4cuITuvyZt7UykjbDcptwnZ9pqIOJA9vFjS7hKW0UgE6fDonKizbuhisIjQw29/17Bz63/8S9JyaqNQ2No+VtJ7JG3JNX/G9oTmNyM/teA5AABWnEJhGxG/kvTqBW0fLFQRAAAtw3ZOAAASI2zROPy+C6BpCFs0SvcwnqWcPo8d1YC6so4788iSXlHnw34Ww1oIjTRM4BK0QP3ZwwduU4NWImzRYN3A7XcjaIFmGCZwmxy0UnmnawQqQaAC7WC78YG6GNZUAAAkxsgWtcAexgDajLBFLbA5GGgH29rwX9+quozaYQ0HAEBihC0AAIkRtgAAJEbYAgCQGGELAEBihC0AAIkRtgAaoXsaTqCJhgpb21ttH7K9O9d2ou17bT+R3Z+Qtdv252zvsb3L9ptTFT9IRGhurr2n/wJWiojQrQ+cpVsfOKvqUoCRDDuyvVnSeQvarpZ0X0Ssl3Rf9liSzpe0PrtNSbqheJkAADTXUGEbEfdLen5B80WSbsmmb5H0gVz7rTHvIUmvsr2mhFoBAGikIr/Zro6IA9n0TyStzqbXSnomN9++rO1lbE/ZnrE9U6AGADWQ78+zs7NVlwPUTik7SMX8XgtL2nMhIqYjYjIiJsuoAUB18v250+lUXQ5QO0XC9mB383B2fyhr3y/plNx8J2dtAACsSEXC9h5Jm7PpzZK+lmv/ULZX8tsk/Ty3uRkAgBVnqEvs2d4m6RxJJ9neJ+mTkj4t6Q7bl0t6WtJl2ezbJV0gaY+kX0v6SMk1A2ihYY+hHTSf7TLKAUo1VNhGxKY+T53bY96QdGWRooY1TOe0veh8EcG1VIGKdY+jHcag+Taf/WAZJQGlavTF44f9hstZZwAAVWp02A4akXZP78bIFag324uOSPMjX0auaCJSCACAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASa3XYcnwtAKAOGn2c7SAcXwu0w6DjcIG6I40AAEiMsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAILGBYWt7q+1Dtnfn2v7J9mO2d9m+2/arsvZ1tn9je2d2+2LC2gEAaIRhRrY3SzpvQdu9kt4YEX8q6UeSPpF7bm9ETGS3K8opEwCA5hoYthFxv6TnF7R9MyIOZw8fknRygtoAAGiFMn6z/aik/8g9PtX292x/2/bZ/V5ke8r2jO2ZEmoAUKF8f56dna26HKB2CoWt7WskHZb05azpgKTxiHiTpL+R9BXbf9jrtRExHRGTETFZpAYA1cv3506nU3U5QO2MHLa2PyzpzyX9ZWRn/I+IFyPiuWx6h6S9kl5XQp0AADTWSGFr+zxJfyvp/RHx61x7x/aqbPo0SeslPVlGoQAANNXAq/7Y3ibpHEkn2d4n6ZOa3/v4lZLutS1JD2V7Hr9D0t/b/p2kOUlXRMTzPd8YAIAVYmDYRsSmHs039Zn3Tkl3Fi0KAIA24QxSAAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiRG2AAAkRtgCAJAYYQsAQGKELQAAiQ0MW9tbbR+yvTvXdq3t/bZ3ZrcLcs99wvYe24/bfl+qwgEAaIphRrY3SzqvR/v1ETGR3bZLku3TJW2UdEb2mi/YXlVWsQAANNHAsI2I+yU9P+T7XSTptoh4MSJ+LGmPpA0F6gMAoPGK/GZ7le1d2WbmE7K2tZKeyc2zL2s7iu0p2zO2ZwrUAKAG8v15dna26nKA2hk1bG+Q9FpJE5IOSLpuqW8QEdMRMRkRkyPWAKAm8v250+lUXQ5QOyOFbUQcjIgjETEn6Ub9flPxfkmn5GY9OWsDAGDFGilsba/JPbxYUndP5XskbbT9StunSlov6TvFSgQAoNmOGTSD7W2SzpF0ku19kj4p6RzbE5JC0lOStkhSRDxi+w5Jj0o6LOnKiDiSpHIAABpiYNhGxKYezTctMv+nJH2qSFEAALQJZ5ACACAxwhYAgMQIWwAAEiNsAQBIjLAFACAxwhYAgMQIWwAAEiNsAQBIjLAFACAxwhYAgMQIWwAAEiNsAQBIjLAFACAxwhYAgMQIWwAAEiNsAQBIbGDY2t5q+5Dt3bm2223vzG5P2d6Zta+z/Zvcc19MWDsAAI1wzBDz3Czp85Ju7TZExF90p21fJ+nnufn3RsRESfUBANB4A8M2Iu63va7Xc7Yt6TJJ7yq5LgAAWqPob7ZnSzoYEU/k2k61/T3b37Z9dr8X2p6yPWN7pmANACqW78+zs7NVlwPUTtGw3SRpW+7xAUnjEfEmSX8j6Su2/7DXCyNiOiImI2KyYA0AKpbvz51Op+pygNoZOWxtHyPpEkm3d9si4sWIeC6b3iFpr6TXFS0SAIAmKzKyfbekxyJiX7fBdsf2qmz6NEnrJT1ZrEQAAJptmEN/tkl6UNLrbe+zfXn21Ea9fBOyJL1D0q7sUKB/k3RFRDxfYr0AADTOMHsjb+rT/uEebXdKurN4WQAAtAdnkAIAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASc0RUXYNsz0r6laSfVl1LCU4Sn6NOmvA5/jgiWnMRWNu/kPR41XWUoAn/d4bB51hePftzLcJWkmzPtOFC8nyOemnL52iStvzN+Rz10vTPwWZkAAASI2wBAEisTmE7XXUBJeFz1EtbPkeTtOVvzueol0Z/jtr8ZgsAQFvVaWQLAEArVR62ts+z/bjtPbavrrqepbD9lO0f2N5peyZrO9H2vbafyO5PqLrOhWxvtX3I9u5cW8+6Pe9z2b/PLttvrq7yl+vzOa61vT/7N9lp+4Lcc5/IPsfjtt9XTdXtRn9efvTnZvTnSsPW9ipJ/yLpfEmnS9pk+/QqaxrBOyNiIrdL+tWS7ouI9ZLuyx7Xzc2SzlvQ1q/u8yWtz25Tkm5YphqHcbOO/hySdH32bzIREdslKft/tVHSGdlrvpD9/0NJ6M+VuVn059r356pHthsk7YmIJyPit5Juk3RRxTUVdZGkW7LpWyR9oLpSeouI+yU9v6C5X90XSbo15j0k6VW21yxLoQP0+Rz9XCTptoh4MSJ+LGmP5v//oTz05wrQn5vRn6sO27WSnsk93pe1NUVI+qbtHbansrbVEXEgm/6JpNXVlLZk/epu4r/RVdkmsq25zX5N/BxN0/S/Mf25nlrRn6sO26Z7e0S8WfObZq60/Y78kzG/q3fjdvduat2ZGyS9VtKEpAOSrqu0GjQJ/bl+WtOfqw7b/ZJOyT0+OWtrhIjYn90fknS35jdjHOxulsnuD1VX4ZL0q7tR/0YRcTAijkTEnKQb9ftNS436HA3V6L8x/bl+2tSfqw7bhyWtt32q7Vdo/gfveyquaSi2j7V9fHda0nsl7dZ8/Zuz2TZL+lo1FS5Zv7rvkfShbC/Gt0n6eW7zVO0s+P3pYs3/m0jzn2Oj7VfaPlXzO4h8Z7nrazn6c33Qn+smIiq9SbpA0o8k7ZV0TdX1LKHu0yR9P7s90q1d0qs1v/ffE5L+n6QTq661R+3bNL9J5nea/63j8n51S7Lm9zDdK+kHkiarrn/A5/i/WZ27NN8h1+Tmvyb7HI9LOr/q+tt4oz9XUjv9uQH9mTNIAQCQWNWbkQEAaD3CFgCAxAhbAAASI2wBAEiMsAUAIDHCFgCAxAhbAAASI2wBAEjs/wMQXySwfs4zLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 產生3張圖像，寬高各為 192，裡面有6個隨機擺放的圖案。\n",
    "input_images, target_masks = simulation.generate_random_data(\n",
    "                                        192, 192, count=3)\n",
    "\n",
    "print(\"input_images shape and range\", input_images.shape, \n",
    "      input_images.min(), input_images.max())\n",
    "print(\"target_masks shape and range\", target_masks.shape, \n",
    "      target_masks.min(), target_masks.max())\n",
    "\n",
    "# 輸入圖像，改為單色\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# 遮罩(Mask)圖像，使用彩色\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "# 顯示圖像：左邊原圖為輸入，右邊遮罩(Mask)圖像為目標\n",
    "\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qg2FqLRGBEJT"
   },
   "source": [
    "## 建立 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-UTr03eAROb"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "# 自訂資料集，一次傳回原圖、遮罩圖像各一個\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = \\\n",
    "            simulation.generate_random_data(192, 192, count=count)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qg2FqLRGBEJT"
   },
   "source": [
    "## 建立 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-UTr03eAROb"
   },
   "outputs": [],
   "source": [
    "# 轉換\n",
    "trans = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "# 產生訓練及驗證圖像各2000筆\n",
    "train_set = SimDataset(2000, transform = trans)\n",
    "val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "  'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "dataloaders = {\n",
    "  'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "  'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtkJTyxGB-XB"
   },
   "source": [
    "## 建立還原轉換函數，並測試一批資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "CRIOwoQvBKPm",
    "outputId": "0ee7b026-9b8e-4fd9-d3a0-3219a6d0c55b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 192, 192]) torch.Size([25, 6, 192, 192])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f538fcda0>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "# 還原轉換\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "\n",
    "# 取得一批資料測試\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "print(inputs.shape, masks.shape)\n",
    "plt.imshow(reverse_transform(inputs[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7XRZIKtCN8E"
   },
   "source": [
    "# 建立 U-Net 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8EJl0hcC5DH"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 載入 resnet18 模型\n",
    "        self.base_model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "\n",
    "        layer0 = self.layer0(input)\n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer4 = self.layer4(layer3)\n",
    "\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "\n",
    "        # 新增神經層\n",
    "        x = self.upsample(x)\n",
    "        # 對面的神經層\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        # 連接新增的神經層及對面的神經層\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJ65Br1oDCOX"
   },
   "source": [
    "## Instantiate the UNet model\n",
    "\n",
    "- Move the model to GPU if available\n",
    "- Show model summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "26c23e86b3144131b1a461204794c75c",
      "da049760188f4fcbbb489bd6112c4465",
      "a56301de9c984f33afb92133a9b695ea",
      "a4a0557cdac841dabc49bb820eee9dda",
      "7f8d3d80a279490a88db38957610eb85",
      "7c346e79cfd54349b4c1741176b75d9d",
      "ddfaa576cef74773a11e1e97aa366530",
      "096d1eecb02c4ef9a6ecee295d865419"
     ]
    },
    "colab_type": "code",
    "id": "bY0Vk2VDCAiz",
    "outputId": "263fdf19-82e4-41ed-d0f7-f2026722b234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c23e86b3144131b1a461204794c75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_unet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "\n",
    "model = ResNetUNet(6)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RaZdFgOnGA_p",
    "outputId": "0fcd0aa5-6718-4490-e595-595a78442572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetUNet(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer0_1x1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer1_1x1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2_1x1): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3_1x1): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4_1x1): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv_up3): Sequential(\n",
       "    (0): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up2): Sequential(\n",
       "    (0): Conv2d(640, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up1): Sequential(\n",
       "    (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up0): Sequential(\n",
       "    (0): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size2): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MoVYhHpbCSdY",
    "outputId": "5ec5dba9-710a-4f0a-e9af-c3a5c35ef31a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           9,408\n",
      "            Conv2d-6         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-7         [-1, 64, 112, 112]             128\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-11           [-1, 64, 56, 56]               0\n",
      "        MaxPool2d-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-14           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-28           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-34           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-36           [-1, 64, 56, 56]             128\n",
      "             ReLU-37           [-1, 64, 56, 56]               0\n",
      "             ReLU-38           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-39           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-40           [-1, 64, 56, 56]               0\n",
      "           Conv2d-41          [-1, 128, 28, 28]          73,728\n",
      "           Conv2d-42          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-48          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "           Conv2d-51          [-1, 128, 28, 28]           8,192\n",
      "           Conv2d-52          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "             ReLU-56          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-57          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-60          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-62          [-1, 128, 28, 28]             256\n",
      "             ReLU-63          [-1, 128, 28, 28]               0\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-66          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "             ReLU-70          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-71          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-72          [-1, 128, 28, 28]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         294,912\n",
      "           Conv2d-74          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "             ReLU-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-82          [-1, 256, 14, 14]             512\n",
      "           Conv2d-83          [-1, 256, 14, 14]          32,768\n",
      "           Conv2d-84          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-86          [-1, 256, 14, 14]             512\n",
      "             ReLU-87          [-1, 256, 14, 14]               0\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-89          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-90          [-1, 256, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-92          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-93          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
      "           Conv2d-98          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "            ReLU-102          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-103          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105            [-1, 512, 7, 7]       1,179,648\n",
      "          Conv2d-106            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-108            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-109            [-1, 512, 7, 7]               0\n",
      "            ReLU-110            [-1, 512, 7, 7]               0\n",
      "          Conv2d-111            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-115            [-1, 512, 7, 7]         131,072\n",
      "          Conv2d-116            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-119            [-1, 512, 7, 7]               0\n",
      "            ReLU-120            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "          Conv2d-123            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-124            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-125            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-126            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-127            [-1, 512, 7, 7]               0\n",
      "            ReLU-128            [-1, 512, 7, 7]               0\n",
      "          Conv2d-129            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-130            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-131            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-132            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-133            [-1, 512, 7, 7]               0\n",
      "            ReLU-134            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-135            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-136            [-1, 512, 7, 7]               0\n",
      "          Conv2d-137            [-1, 512, 7, 7]         262,656\n",
      "            ReLU-138            [-1, 512, 7, 7]               0\n",
      "        Upsample-139          [-1, 512, 14, 14]               0\n",
      "          Conv2d-140          [-1, 256, 14, 14]          65,792\n",
      "            ReLU-141          [-1, 256, 14, 14]               0\n",
      "          Conv2d-142          [-1, 512, 14, 14]       3,539,456\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "        Upsample-144          [-1, 512, 28, 28]               0\n",
      "          Conv2d-145          [-1, 128, 28, 28]          16,512\n",
      "            ReLU-146          [-1, 128, 28, 28]               0\n",
      "          Conv2d-147          [-1, 256, 28, 28]       1,474,816\n",
      "            ReLU-148          [-1, 256, 28, 28]               0\n",
      "        Upsample-149          [-1, 256, 56, 56]               0\n",
      "          Conv2d-150           [-1, 64, 56, 56]           4,160\n",
      "            ReLU-151           [-1, 64, 56, 56]               0\n",
      "          Conv2d-152          [-1, 256, 56, 56]         737,536\n",
      "            ReLU-153          [-1, 256, 56, 56]               0\n",
      "        Upsample-154        [-1, 256, 112, 112]               0\n",
      "          Conv2d-155         [-1, 64, 112, 112]           4,160\n",
      "            ReLU-156         [-1, 64, 112, 112]               0\n",
      "          Conv2d-157        [-1, 128, 112, 112]         368,768\n",
      "            ReLU-158        [-1, 128, 112, 112]               0\n",
      "        Upsample-159        [-1, 128, 224, 224]               0\n",
      "          Conv2d-160         [-1, 64, 224, 224]         110,656\n",
      "            ReLU-161         [-1, 64, 224, 224]               0\n",
      "          Conv2d-162          [-1, 6, 224, 224]             390\n",
      "================================================================\n",
      "Total params: 28,976,646\n",
      "Trainable params: 28,976,646\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 417.65\n",
      "Params size (MB): 110.54\n",
      "Estimated Total Size (MB): 528.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7rAEQCUEI2v"
   },
   "source": [
    "## 定義損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjt9JeTuDY6D"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import dice_loss\n",
    "\n",
    "checkpoint_path = \"checkpoint.pth\"\n",
    "\n",
    "# 損失採 binary cross entropy + dice loss\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = torch.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# 計算效能衡量指標\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(f\"{k}: {(metrics[k] / epoch_samples):4f}\")\n",
    "\n",
    "    print(f\"{phase}: {\", \".join(outputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7rAEQCUEI2v"
   },
   "source": [
    "## 建立訓練及評估函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjt9JeTuDY6D"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            if phase == 'train':\n",
    "            scheduler.step()\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(\"LR\", param_group['lr'])\n",
    "\n",
    "            # save the model weights\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(f\"saving best model to {checkpoint_path}\")\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7rAEQCUEI2v"
   },
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RfxgL303EMiy",
    "outputId": "513c2eba-d6b6-4b5f-d223-590b2c074ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train: bce: 0.105508, dice: 0.960730, loss: 0.533119\n",
      "LR 0.0001\n",
      "val: bce: 0.021507, dice: 0.793499, loss: 0.407503\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 1/9\n",
      "----------\n",
      "train: bce: 0.013632, dice: 0.554114, loss: 0.283873\n",
      "LR 0.0001\n",
      "val: bce: 0.004518, dice: 0.269733, loss: 0.137125\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 2/9\n",
      "----------\n",
      "train: bce: 0.003263, dice: 0.147794, loss: 0.075529\n",
      "LR 0.0001\n",
      "val: bce: 0.002220, dice: 0.087164, loss: 0.044692\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 3/9\n",
      "----------\n",
      "train: bce: 0.002458, dice: 0.081096, loss: 0.041777\n",
      "LR 0.0001\n",
      "val: bce: 0.001856, dice: 0.059757, loss: 0.030807\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 4/9\n",
      "----------\n",
      "train: bce: 0.002173, dice: 0.062749, loss: 0.032461\n",
      "LR 0.0001\n",
      "val: bce: 0.001647, dice: 0.048988, loss: 0.025317\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 5/9\n",
      "----------\n",
      "train: bce: 0.001924, dice: 0.052670, loss: 0.027297\n",
      "LR 0.0001\n",
      "val: bce: 0.001413, dice: 0.040671, loss: 0.021042\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 6/9\n",
      "----------\n",
      "train: bce: 0.001629, dice: 0.044960, loss: 0.023295\n",
      "LR 0.0001\n",
      "val: bce: 0.001336, dice: 0.037718, loss: 0.019527\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 7/9\n",
      "----------\n",
      "train: bce: 0.001435, dice: 0.040354, loss: 0.020895\n",
      "LR 1e-05\n",
      "val: bce: 0.001220, dice: 0.035549, loss: 0.018385\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 8/9\n",
      "----------\n",
      "train: bce: 0.001252, dice: 0.036088, loss: 0.018670\n",
      "LR 1e-05\n",
      "val: bce: 0.001170, dice: 0.033778, loss: 0.017474\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Epoch 9/9\n",
      "----------\n",
      "train: bce: 0.001239, dice: 0.035437, loss: 0.018338\n",
      "LR 1e-05\n",
      "val: bce: 0.001162, dice: 0.033512, loss: 0.017337\n",
      "saving best model to checkpoint.pth\n",
      "0m 22s\n",
      "Best val loss: 0.017337\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "\n",
    "num_class = 6\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "for l in model.base_layers:\n",
    "    for param in l.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcRgjfk5D-kP"
   },
   "source": [
    "## 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "xXRtpxHRET-v",
    "outputId": "3e1520e5-fec2-401d-dde2-8900b760f442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape torch.Size([3, 3, 192, 192])\n",
      "labels.shape torch.Size([3, 6, 192, 192])\n",
      "pred.shape (3, 6, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# 建立新資料\n",
    "test_dataset = SimDataset(3, transform = trans)\n",
    "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "\n",
    "# 取一批資料測試\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "print('inputs.shape', inputs.shape)\n",
    "print('labels.shape', labels.shape)\n",
    "\n",
    "# 預測\n",
    "model.eval()   \n",
    "pred = model(inputs)\n",
    "pred = torch.sigmoid(pred) # 轉為 [0, 1] 之間\n",
    "pred = pred.data.cpu().numpy()\n",
    "print('pred.shape', pred.shape)\n",
    "\n",
    "# 原圖還原轉換\n",
    "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "# 遮罩\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "\n",
    "# 預測轉成圖像\n",
    "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "## 左邊: 原圖, 中間: 遮罩圖像(target), 右邊: 預測圖像\n",
    "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wsfxcw0-DZdn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPG4VNTnFr3p"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Try tweaking the hyper-parameters for better accuracy e.g.\n",
    "\n",
    "- learning rates and schedules\n",
    "- loss weights\n",
    "- unfreezing layers\n",
    "- batch size\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7VHV2fS4GRd-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOdlE+t0YU4MFBwMIqB8ltC",
   "include_colab_link": true,
   "name": "pytorch-unet-resnet18-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "096d1eecb02c4ef9a6ecee295d865419": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26c23e86b3144131b1a461204794c75c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a56301de9c984f33afb92133a9b695ea",
       "IPY_MODEL_a4a0557cdac841dabc49bb820eee9dda"
      ],
      "layout": "IPY_MODEL_da049760188f4fcbbb489bd6112c4465"
     }
    },
    "7c346e79cfd54349b4c1741176b75d9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f8d3d80a279490a88db38957610eb85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a4a0557cdac841dabc49bb820eee9dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_096d1eecb02c4ef9a6ecee295d865419",
      "placeholder": "​",
      "style": "IPY_MODEL_ddfaa576cef74773a11e1e97aa366530",
      "value": " 44.7M/44.7M [00:54&lt;00:00, 862kB/s]"
     }
    },
    "a56301de9c984f33afb92133a9b695ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c346e79cfd54349b4c1741176b75d9d",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f8d3d80a279490a88db38957610eb85",
      "value": 46827520
     }
    },
    "da049760188f4fcbbb489bd6112c4465": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddfaa576cef74773a11e1e97aa366530": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
