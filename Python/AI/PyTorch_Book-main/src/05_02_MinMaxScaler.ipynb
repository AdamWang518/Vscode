{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手寫阿拉伯數字辨識 正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DATASETS = \"std\" # 預設路徑\n",
    "BATCH_SIZE = 1024  # 批量\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟1：載入 MNIST 手寫阿拉伯數字資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "# 下載 MNIST 手寫阿拉伯數字 訓練資料\n",
    "train_ds = MNIST(PATH_DATASETS, train=True, download=True, \n",
    "                 transform=transform)\n",
    "\n",
    "# 下載測試資料\n",
    "test_ds = MNIST(PATH_DATASETS, train=False, download=True, \n",
    "                 transform=transform)\n",
    "\n",
    "# 訓練/測試資料的維度\n",
    "print(train_ds.data.shape, test_ds.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練資料前10筆圖片的數字\n",
    "train_ds.targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示第1張圖片內含值\n",
    "train_ds.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000001111111111110000',\n",
       " '0000000011111111111111110000',\n",
       " '0000000111111111111111100000',\n",
       " '0000000111111111110000000000',\n",
       " '0000000011111110110000000000',\n",
       " '0000000001111100000000000000',\n",
       " '0000000000011110000000000000',\n",
       " '0000000000011110000000000000',\n",
       " '0000000000001111110000000000',\n",
       " '0000000000000111111000000000',\n",
       " '0000000000000011111100000000',\n",
       " '0000000000000001111100000000',\n",
       " '0000000000000000011110000000',\n",
       " '0000000000000011111110000000',\n",
       " '0000000000001111111100000000',\n",
       " '0000000000111111111000000000',\n",
       " '0000000011111111110000000000',\n",
       " '0000001111111111000000000000',\n",
       " '0000111111111100000000000000',\n",
       " '0000111111110000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將非0的數字轉為1，顯示第1張圖片\n",
    "data = train_ds.data[0].clone()\n",
    "data = data.numpy()\n",
    "data[data>0]=1\n",
    "data = data.astype(int)\n",
    "\n",
    "# 將轉換後二維內容顯示出來，隱約可以看出數字為 5\n",
    "text_image=[]\n",
    "for i in range(data.shape[0]):\n",
    "    text_image.append(''.join(data[i].astype(str)))\n",
    "text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000001111100000000',\n",
       " '0000000000000011111100000000',\n",
       " '0000000000000111111111000000',\n",
       " '0000000000011111111111000000',\n",
       " '0000000000011111111111000000',\n",
       " '0000000000111111111111000000',\n",
       " '0000000001111111110011100000',\n",
       " '0000000011111100000011100000',\n",
       " '0000000111111100000011100000',\n",
       " '0000000111100000000011100000',\n",
       " '0000000111000000000011100000',\n",
       " '0000001111000000000011100000',\n",
       " '0000001111000000001111100000',\n",
       " '0000001110000000011111000000',\n",
       " '0000001110000000111100000000',\n",
       " '0000001110000001111000000000',\n",
       " '0000001111111111111000000000',\n",
       " '0000001111111111100000000000',\n",
       " '0000001111111110000000000000',\n",
       " '0000000111111100000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將非0的數字轉為1，顯示第2張圖片\n",
    "data = train_ds.data[1].clone()\n",
    "data = data.numpy()\n",
    "data[data>0]=1\n",
    "data = data.astype(int)\n",
    "\n",
    "# 將轉換後二維內容顯示出來，隱約可以看出數字為 5\n",
    "text_image=[]\n",
    "for i in range(data.shape[0]):\n",
    "    text_image.append(''.join(data[i].astype(str)))\n",
    "text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第1張圖片圖像\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 第一筆資料\n",
    "X = train_ds.data[0]\n",
    "\n",
    "# 繪製點陣圖，cmap='gray':灰階\n",
    "plt.imshow(X.reshape(28,28), cmap='gray')\n",
    "\n",
    "# 隱藏刻度\n",
    "plt.axis('off') \n",
    "\n",
    "# 顯示圖形\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟2：資料清理，此步驟無需進行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟3：進行特徵工程，將特徵縮放成(0, 1)之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化\n",
    "train_ds.data = train_ds.data / 255.0\n",
    "test_ds.data = test_ds.data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟4：資料分割，此步驟無需進行，載入MNIST資料時，已經切割好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟5：建立模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 * 28, 256), \n",
    "    nn.Dropout(0.2),\n",
    "    torch.nn.Linear(256, 10), \n",
    "    # 使用nn.CrossEntropyLoss()時，不需要將輸出經過softmax層，否則計算的損失會有誤\n",
    "    #torch.nn.Softmax(dim=1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟6：結合訓練資料及模型，進行模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [    0 / 60000] (0 %)  Loss: 2.320893\n",
      "Epoch 1: [ 6000 / 60000] (10 %)  Loss: 21.058321\n",
      "Epoch 1: [12000 / 60000] (20 %)  Loss: 14.615396\n",
      "Epoch 1: [18000 / 60000] (30 %)  Loss: 7.272960\n",
      "Epoch 1: [24000 / 60000] (40 %)  Loss: 5.849614\n",
      "Epoch 1: [30000 / 60000] (50 %)  Loss: 4.201842\n",
      "Epoch 1: [36000 / 60000] (60 %)  Loss: 2.784539\n",
      "Epoch 1: [42000 / 60000] (70 %)  Loss: 1.921148\n",
      "Epoch 1: [48000 / 60000] (80 %)  Loss: 1.669999\n",
      "Epoch 1: [54000 / 60000] (90 %)  Loss: 1.642164\n",
      "Epoch 2: [    0 / 60000] (0 %)  Loss: 1.864826\n",
      "Epoch 2: [ 6000 / 60000] (10 %)  Loss: 1.626204\n",
      "Epoch 2: [12000 / 60000] (20 %)  Loss: 1.590835\n",
      "Epoch 2: [18000 / 60000] (30 %)  Loss: 1.563107\n",
      "Epoch 2: [24000 / 60000] (40 %)  Loss: 1.688237\n",
      "Epoch 2: [30000 / 60000] (50 %)  Loss: 1.773960\n",
      "Epoch 2: [36000 / 60000] (60 %)  Loss: 1.582444\n",
      "Epoch 2: [42000 / 60000] (70 %)  Loss: 1.694004\n",
      "Epoch 2: [48000 / 60000] (80 %)  Loss: 1.505382\n",
      "Epoch 2: [54000 / 60000] (90 %)  Loss: 1.596213\n",
      "Epoch 3: [    0 / 60000] (0 %)  Loss: 1.596984\n",
      "Epoch 3: [ 6000 / 60000] (10 %)  Loss: 1.462517\n",
      "Epoch 3: [12000 / 60000] (20 %)  Loss: 1.582490\n",
      "Epoch 3: [18000 / 60000] (30 %)  Loss: 1.503246\n",
      "Epoch 3: [24000 / 60000] (40 %)  Loss: 1.622499\n",
      "Epoch 3: [30000 / 60000] (50 %)  Loss: 1.706902\n",
      "Epoch 3: [36000 / 60000] (60 %)  Loss: 1.599397\n",
      "Epoch 3: [42000 / 60000] (70 %)  Loss: 1.768751\n",
      "Epoch 3: [48000 / 60000] (80 %)  Loss: 1.630874\n",
      "Epoch 3: [54000 / 60000] (90 %)  Loss: 1.672794\n",
      "Epoch 4: [    0 / 60000] (0 %)  Loss: 1.704173\n",
      "Epoch 4: [ 6000 / 60000] (10 %)  Loss: 1.452591\n",
      "Epoch 4: [12000 / 60000] (20 %)  Loss: 1.740950\n",
      "Epoch 4: [18000 / 60000] (30 %)  Loss: 1.437251\n",
      "Epoch 4: [24000 / 60000] (40 %)  Loss: 1.696324\n",
      "Epoch 4: [30000 / 60000] (50 %)  Loss: 1.717468\n",
      "Epoch 4: [36000 / 60000] (60 %)  Loss: 1.624833\n",
      "Epoch 4: [42000 / 60000] (70 %)  Loss: 1.776798\n",
      "Epoch 4: [48000 / 60000] (80 %)  Loss: 1.565546\n",
      "Epoch 4: [54000 / 60000] (90 %)  Loss: 1.722985\n",
      "Epoch 5: [    0 / 60000] (0 %)  Loss: 1.601343\n",
      "Epoch 5: [ 6000 / 60000] (10 %)  Loss: 1.524248\n",
      "Epoch 5: [12000 / 60000] (20 %)  Loss: 1.843043\n",
      "Epoch 5: [18000 / 60000] (30 %)  Loss: 1.519737\n",
      "Epoch 5: [24000 / 60000] (40 %)  Loss: 1.767884\n",
      "Epoch 5: [30000 / 60000] (50 %)  Loss: 1.791379\n",
      "Epoch 5: [36000 / 60000] (60 %)  Loss: 1.644929\n",
      "Epoch 5: [42000 / 60000] (70 %)  Loss: 1.751241\n",
      "Epoch 5: [48000 / 60000] (80 %)  Loss: 1.546112\n",
      "Epoch 5: [54000 / 60000] (90 %)  Loss: 1.875843\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr=0.1\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=600)\n",
    "\n",
    "# 設定優化器(optimizer)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "loss_list = []    \n",
    "for epoch in range(1, epochs + 1):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "#         if batch_idx == 0 and epoch == 1: print(data[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        # loss = nn.functional.nll_loss(output, target) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            loss_list.append(loss.item())\n",
    "            batch = batch_idx * len(data)\n",
    "            data_count = len(train_loader.dataset)\n",
    "            percentage = (100. * batch_idx / len(train_loader))\n",
    "            print(f'Epoch {epoch}: [{batch:5d} / {data_count}] ({percentage:.0f} %)' +\n",
    "                  f'  Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23ac3c007c0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 對訓練過程的損失繪圖\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_list, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟7：評分(Score Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均損失: 1.8549, 準確率: 4569/10000 (46%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 建立 DataLoader\n",
    "test_loader = DataLoader(test_ds, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # test_loss += nn.functional.nll_loss(output, target).item()\n",
    "        \n",
    "        # 預測\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        \n",
    "        # 正確筆數\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "# 平均損失\n",
    "data_count = len(test_loader.dataset)\n",
    "test_loss /= data_count\n",
    "# 顯示測試結果\n",
    "percentage = 100. * correct / data_count\n",
    "print(f'平均損失: {test_loss:.4f}, 準確率: {correct}/{data_count}' + \n",
    "      f' ({percentage:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual    : [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "prediction:  7 2 1 0 4 1 4 9 5 7 0 2 7 8 1 6 9 7 2 4\n"
     ]
    }
   ],
   "source": [
    "# 實際預測 20 筆資料\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        data, target = test_ds[i][0], test_ds[i][1]\n",
    "        data = data.reshape(1, *data.shape).to(device)\n",
    "        output = torch.argmax(model(data), axis=-1)\n",
    "        predictions.append(str(output.item()))\n",
    "\n",
    "# 比對\n",
    "print('actual    :', test_ds.targets[0:20].numpy())\n",
    "print('prediction: ', ' '.join(predictions[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~9預測機率: [[0.   0.   0.   0.   0.03 0.97 0.   0.   0.   0.  ]]\n",
      "0~9預測機率: [5]\n"
     ]
    }
   ],
   "source": [
    "# 顯示第 9 筆的機率\n",
    "import numpy as np\n",
    "\n",
    "i=8\n",
    "data = test_ds[i][0]\n",
    "data = data.reshape(1, *data.shape).to(device)\n",
    "#print(data.shape)\n",
    "predictions = torch.softmax(model(data), dim=1)\n",
    "print(f'0~9預測機率: {np.around(predictions.cpu().detach().numpy(), 2)}')\n",
    "print(f'0~9預測機率: {np.argmax(predictions.cpu().detach().numpy(), axis=-1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEZ0lEQVR4nO3dsUpcWxiAUUfS+B6SPj5A2vT2QgpbCT5BJHYpbGws7H0AyxSKKfME1oKkEivbud2FC84+4LmDn7hWOZvtL+LHhtlwzmK5XG4APZuv/QsAzxMnRIkTosQJUeKEqA+jxcVi4atcWLPlcrl47nMnJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRH177F+C/fv78OVxfLpezfv7l5eVw/cePHy+e/f379+H65ub4LDg6OkrOnpo/d/bKfS/aBaydOCFKnBAlTogSJ0SJE6LECVGL0f3N8fHx8HJpzp3br1+/hutfvnwZrs+59/r8+fNw78HBwazZU05PT1euzblv29iYf+d2c3MzXOf/t1wuF8997uSEKHFClDghSpwQJU6IEidEiROihveci8Vi3oUeMMk9J7wx4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMq+AvDs7Gy4PufxlBcXF8P1vb29WbOnHk/58ePHlWvn5+drnX1/fz9cv76+XtvsqcduVmdPzZ87exUnJ0SJE6LECVHihChxQpQ4IUqcEDW857y9vR1unnP39Pfv3+Her1+/rm32YvHskwj/tb+/P2v23d3dcH1077W9vT1r9tT+qXvOqb/NOr3X2as4OSFKnBAlTogSJ0SJE6LECVHihCivAIRX5hWA8MaIE6LECVHihChxQpQ4IUqcEJV9bi3vz8nJycq1uc+t3dnZGa7v7u4O1+c8t/bTp0/D9VWcnBAlTogSJ0SJE6LECVHihKjhVcrT09Nw85yvt//8+TPce3V1tbbZv3//Hu6d8zq4qdkbG+NHY77m7Kn56559eHj44tmPj4+zZn/79m24Ppr/8PAwa/YqTk6IEidEiROixAlR4oQocUKUOCFqeM+5tbU13Dx19zS1f2TuK9mKr3R7C97ra/iK/y9OTogSJ0SJE6LECVHihChxQpQ4IWr4CkDg9Tg5IUqcECVOiBInRIkTosQJUf8AH4n0vlyqfukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第 9 筆圖像\n",
    "X2 = test_ds[i][0] \n",
    "plt.imshow(X2.reshape(28,28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟8：評估，暫不進行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟9：模型佈署"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟10：新資料預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual/prediction: 0 6\n",
      "actual/prediction: 1 6\n",
      "actual/prediction: 2 6\n",
      "actual/prediction: 3 6\n",
      "actual/prediction: 4 6\n",
      "actual/prediction: 5 6\n",
      "actual/prediction: 6 6\n",
      "actual/prediction: 7 6\n",
      "actual/prediction: 8 6\n",
      "actual/prediction: 9 6\n"
     ]
    }
   ],
   "source": [
    "# 使用小畫家，繪製 0~9，實際測試看看\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# 讀取影像並轉為單色\n",
    "for i in range(10):\n",
    "    uploaded_file = f'./myDigits/{i}.png'\n",
    "    image1 = Image.open(uploaded_file).convert('L')\n",
    "\n",
    "    # 縮為 (28, 28) 大小的影像\n",
    "    image_resized = np.asarray(image1.resize((28, 28)))\n",
    "    X1 = image_resized.reshape(1,28, 28) / 255.0\n",
    "\n",
    "    # 反轉顏色，顏色0為白色，與 RGB 色碼不同，它的 0 為黑色\n",
    "    X1 = torch.FloatTensor(1-X1).to(device)\n",
    "\n",
    "    # 預測\n",
    "    predictions = torch.softmax(model(X1), dim=1)\n",
    "    # print(np.around(predictions.cpu().detach().numpy(), 2))\n",
    "    print(f'actual/prediction: {i} {np.argmax(predictions.detach().cpu().numpy())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1333, 0.5882, 0.6353, 0.6353, 0.6353, 0.5216, 0.1765, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137,\n",
       "          0.7882, 0.4078, 0.2157, 0.2157, 0.2275, 0.4157, 0.7333, 0.6000,\n",
       "          0.0941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5725,\n",
       "          0.4431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353, 0.4667,\n",
       "          0.7725, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7412,\n",
       "          0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.8000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.7059,\n",
       "          0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.7961, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.7490,\n",
       "          0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.8000,\n",
       "          0.6078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5647,\n",
       "          0.4549, 0.0000, 0.0000, 0.0000, 0.0275, 0.3686, 0.7647, 0.9255,\n",
       "          0.2941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
       "          0.7882, 0.3569, 0.1490, 0.4157, 0.7255, 0.6118, 0.2706, 0.7451,\n",
       "          0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1529, 0.6627, 0.6863, 0.5569, 0.1529, 0.0000, 0.4941, 0.4745,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.7569, 0.0902,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3843, 0.5922, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.7412, 0.1765, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.4118, 0.5882, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0863, 0.7725, 0.1333, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5294, 0.4667, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0627, 0.7569, 0.0784, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4235, 0.5569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0392, 0.7608, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3490, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.6667, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0784, 0.7255, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0196, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = [file_name for file_name in os.listdir(img_dir)]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 組合檔案完整路徑\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[idx])\n",
    "        # 讀取圖檔\n",
    "        image = read_image(img_path)\n",
    "        if image.shape[0]>3:\n",
    "            image = image[1:,:,:]\n",
    "        # 去除副檔名\n",
    "        label = self.img_labels[idx].split('.')[0]\n",
    "        label = int(label)\n",
    "        \n",
    "        # 轉換\n",
    "        # print(type(image))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        \n",
    "        # 將三維轉為二維\n",
    "        image = image.reshape(*image.shape[1:])\n",
    "        # 反轉顏色，顏色0為白色，與 RGB 色碼不同，它的 0 為黑色\n",
    "        image = 1.0-image\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均損失: 4.0483, 準確率: 1/10 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 建立 transforms\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.CenterCrop(28),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "])\n",
    "\n",
    "# 建立 DataLoader\n",
    "test_loader = DataLoader(CustomImageDataset('./myDigits', transform)\n",
    "                         , shuffle=False, batch_size=10)\n",
    "\n",
    "model.eval()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        \n",
    "        # 預測\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        \n",
    "        # 正確筆數\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "# 平均損失\n",
    "test_loss /= len(test_loader.dataset)\n",
    "# 顯示測試結果\n",
    "data_count = len(test_loader.dataset)\n",
    "percentage = 100. * correct / data_count\n",
    "print(f'平均損失: {test_loss:.4f}, 準確率: {correct}/{data_count}' + \n",
    "      f' ({percentage:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
